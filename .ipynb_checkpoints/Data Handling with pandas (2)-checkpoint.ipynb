{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "-Pandas is an open-source, BSD-licensed Python library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "\n",
    "- Most widely used tool for data minging. It contains high-level data structures and manipulation tools designed to make data analysis and fast and flexible data acess to relational data.\n",
    "\n",
    "-they are defined as two-dimensional labeled data structures with columns of potentially different types\n",
    "\n",
    "- Two primary data structures in pandas are series and DataFrame.\n",
    "\n",
    "- Panadas has a lot of built in functions that can be applied directly on DataFrame Series.\n",
    "\n",
    "- To install pandas : pip install pandas\n",
    "\n",
    "- Pandas comes with default Anaconda package.\n",
    "\n",
    "- To use pandas we need to first import it. Syntax: import pandas\n",
    "\n",
    "- To check pandas version. pandas.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\pankaj agarwal\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\pankaj agarwal\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pankaj agarwal\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\pankaj agarwal\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pankaj agarwal\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Features of Pandas\n",
    "#####  Fast and efficient DataFrame object with default and customized indexing.\n",
    "\n",
    "#####  Tools for loading data into in-memory data objects from different file formats.\n",
    "\n",
    "##### Data alignment and integrated handling of missing data.\n",
    "\n",
    "##### Reshaping and pivoting of date sets.\n",
    "\n",
    "##### Label-based slicing, indexing and subsetting of large data sets.\n",
    "\n",
    "##### Columns from a data structure can be deleted or inserted.\n",
    "\n",
    "##### Group by data for aggregation and transformations.\n",
    "\n",
    "##### High performance merging and joining of data.\n",
    "\n",
    "##### Time Series functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series:\n",
    "Series is one dimensional(1-D) array defined in pandas that can be used to store any data type.\n",
    "\n",
    "import pandas as pd\n",
    "##### Create series with Data, and Index \n",
    "a = pd.Series(Data, index = Index)   \n",
    "Here, Data can be:\n",
    "\n",
    "-A Scalar value which can be integerValue, string\n",
    "-A Python Dictionary which can be Key, Value pair\n",
    "-A Ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 4, 5, 6, 2, 9]\n",
      "0    1\n",
      "1    3\n",
      "2    4\n",
      "3    5\n",
      "4    6\n",
      "5    2\n",
      "6    9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "Data =[1, 3, 4, 5, 6, 2, 9]   \n",
    "print(Data)\n",
    "# Creating series with default index values \n",
    "s = pd.Series(Data)     \n",
    "print(s)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3\n",
       "2    4\n",
       "3    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    3\n",
      "c    4\n",
      "d    5\n",
      "e    6\n",
      "f    2\n",
      "g    9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# predefined index values \n",
    "Index =['a', 'b', 'c', 'd', 'e', 'f', 'g']  \n",
    "  \n",
    "# Creating series with predefined index values \n",
    "si = pd.Series(Data, Index) \n",
    "print(si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si['d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "e    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dictionary ={'a':1, 'b':2, 'c':3, 'd':4, 'e':5}  \n",
    "\n",
    "# Creating series of Dictionary type \n",
    "sd = pd.Series(dictionary)  \n",
    "print(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 4], [5, 6, 7], [8, 9, 11]]\n",
      "0     [2, 3, 4]\n",
      "1     [5, 6, 7]\n",
      "2    [8, 9, 11]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "Data =[[2, 3, 4], [5, 6, 7],[8,9,11]]   \n",
    "print(Data) \n",
    "# Creating series of 2darray \n",
    "snd = pd.Series(Data)     \n",
    "print(snd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data Frame\n",
    "DataFrames is two-dimensional(2-D) data structure defined in pandas which consists of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "  \n",
    "# Create DataFrame with Data \n",
    "a = pd.DataFrame(Data)   \n",
    "\n",
    "Here, Data can be:\n",
    "\n",
    "-One or more dictionaries\n",
    "-One or more Series\n",
    "-2D-numpy Ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0\n",
      "0  1\n",
      "1  3\n",
      "2  4\n",
      "3  5\n",
      "4  6\n",
      "5  2\n",
      "6  9\n"
     ]
    }
   ],
   "source": [
    "a = pd.DataFrame(Data)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1st': {'a': 1, 'b': 2, 'c': 3, 'd': 4}, '2nd': {'a': 5, 'b': 6, 'c': 7, 'e': 8, 'f': 9}}\n",
      "   1st  2nd\n",
      "a  1.0  5.0\n",
      "b  2.0  6.0\n",
      "c  3.0  7.0\n",
      "d  4.0  NaN\n",
      "e  NaN  8.0\n",
      "f  NaN  9.0\n"
     ]
    }
   ],
   "source": [
    "# Program to Create Data Frame with two dictionaries \n",
    "dict1 ={'a':1, 'b':2, 'c':3, 'd':4}        # Define Dictionary 1 \n",
    "dict2 ={'a':5, 'b':6, 'c':7, 'e':8, 'f':9} # Define Dictionary 2 \n",
    "Data = {'1st':dict1, '2nd':dict2}\n",
    "print(Data)\n",
    "# Define Data with dict1 and dict2 \n",
    "df = pd.DataFrame(Data)  # Create DataFrame \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   first  second third\n",
      "0      1     1.1     a\n",
      "1      3     3.5     b\n",
      "2      4     4.7     c\n",
      "3      5     5.8     d\n",
      "4      6     2.9     e\n",
      "5      2     9.3   NaN\n",
      "6      9     NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Define series 1 \n",
    "s1 = pd.Series([1, 3, 4, 5, 6, 2, 9])    \n",
    "# Define series 2        \n",
    "s2 = pd.Series([1.1, 3.5, 4.7, 5.8, 2.9, 9.3])  \n",
    "# Define series 3 \n",
    "s3 = pd.Series(['a', 'b', 'c', 'd', 'e'])      \n",
    "  \n",
    "# Define Data \n",
    "Data ={'first':s1, 'second':s2, 'third':s3}  \n",
    "  \n",
    "# Create DataFrame \n",
    "dfseries = pd.DataFrame(Data)        \n",
    "print(dfseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       first     second\n",
      "0  [2, 3, 4]  [2, 4, 8]\n",
      "1  [5, 6, 7]  [1, 3, 9]\n"
     ]
    }
   ],
   "source": [
    "# Program to create DataFrame from 2D array \n",
    "import pandas as pd # Import Library \n",
    "d1 =[[2, 3, 4], [5, 6, 7]] # Define 2d array 1 \n",
    "d2 =[[2, 4, 8], [1, 3, 9]] # Define 2d array 2 \n",
    "Data ={'first': d1, 'second': d2} # Define Data  \n",
    "df2d = pd.DataFrame(Data)    # Create DataFrame \n",
    "print(df2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('01/01/2019', 17, 7, 'Rain'), ('01/02/2019', 29, 5, 'Sunny'), ('01/03/2019', 32, 3, 'Snow')]\n",
      "            0   1  2      3\n",
      "0  01/01/2019  17  7   Rain\n",
      "1  01/02/2019  29  5  Sunny\n",
      "2  01/03/2019  32  3   Snow\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "weather_data = [\n",
    "('01/01/2019', 17, 7, 'Rain'),\n",
    "('01/02/2019', 29, 5, 'Sunny'),\n",
    "('01/03/2019', 32, 3, 'Snow')\n",
    "]\n",
    "print(weather_data)\n",
    "\n",
    "d=pd.DataFrame(weather_data)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    " D={'first':s1, 'second':s2, 'third':s3}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temp</th>\n",
       "      <th>wind speed</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/02/2019</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/03/2019</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>Snow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  temp  wind speed   type\n",
       "0  01/01/2019    17           7   Rain\n",
       "1  01/02/2019    29           5  Sunny\n",
       "2  01/03/2019    32           3   Snow"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd = pd.DataFrame(weather_data,columns=['date','temp','wind speed','type'])\n",
    "wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd.to_csv('d:\\\\weather.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sunny'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd.loc[1]['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   first  second third\n",
      "0      1     1.1     a\n",
      "1      3     3.5     b\n",
      "2      4     4.7     c\n",
      "3      5     5.8     d\n",
      "4      6     2.9     e\n",
      "5      2     9.3   NaN\n",
      "6      9     NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "s1 = pd.Series([1, 3, 4, 5, 6, 2, 9])           # Define series 1 \n",
    "s2 = pd.Series([1.1, 3.5, 4.7, 5.8, 2.9, 9.3]) # Define series 2 \n",
    "s3 = pd.Series(['a', 'b', 'c', 'd', 'e'])     # Define series 3 \n",
    "\n",
    "Data ={'first':s1, 'second':s2, 'third':s3} # Define Data \n",
    "dfseries = pd.DataFrame(Data)\n",
    "print(dfseries)\n",
    "dfseries.to_csv('d:\\\\dfseries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pankaj  hansika  parth\n",
      "0       0        4      8\n",
      "1       1        5      9\n",
      "2       2        6     10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "  \n",
    "# assigning three series to s1, s2, s3 \n",
    "s1 = pd.Series([0, 4, 8]) \n",
    "s2 = pd.Series([1, 5, 9]) \n",
    "s3 = pd.Series([2, 6, 10]) \n",
    "  \n",
    "# taking index and column values \n",
    "dframe = pd.DataFrame([s1, s2, s3]) \n",
    "  \n",
    "# assign column name \n",
    "dframe.columns =['Pankaj', 'hansika', 'parth'] \n",
    "print(dframe) \n",
    "# write data to csv file \n",
    "dframe.to_csv('d:\\\\mycsvwithoutindex.csv', index = False)   \n",
    "dframe.to_csv('d:\\\\mycsvwithIndex.csv', index = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How To Select an Index or Column From a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pankaj  hansika  parth\n",
      "0       0        4      8\n",
      "1       1        5      9\n",
      "2       2        6     10\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(dframe)\n",
    "print(dframe.iloc[0][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(dframe.loc[1]['parth'])\n",
    "print(dframe.iloc[2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-loc[] works on labels of your index. This means that if you give in loc[2], you look for the values of your DataFrame that have an index labeled 2.\n",
    "\n",
    "-iloc[] works on the positions in your index. This means that if you give in iloc[2], you look for the values of your DataFrame that are at index ’2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pankaj</th>\n",
       "      <th>hansika</th>\n",
       "      <th>parth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pankaj  hansika  parth\n",
       "0       0        4      8\n",
       "1       1        5      9\n",
       "2       2        6     12"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dframe.iloc[2,2]=12\n",
    "dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe.loc[1][1]=10\n",
    "dframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling tabular Data with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "methods: read_table, read_csv, read_excel.\n",
    "\n",
    "-read_table can be as a \"generic\" importer for other formats\n",
    "-read_table is read_csv with sep=',' replaced by sep='\\t', they are two thin wrappers around the same function so the performance will be identical\n",
    "-CSV and tab-delimited text (.txt) are equivalent in read and write speed, both are much faster than reading and writing MS Excel files. \n",
    "-However, Excel format compresses the file size a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_width  petal_length  petal_width\n",
      "0          3.5           1.4          0.2\n",
      "1          3.0           1.4          0.2\n",
      "2          3.2           1.3          0.2\n",
      "3          3.1           1.5          0.2\n",
      "4          3.6           1.4          0.2\n",
      "(150, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('d://MLDataset//iris_dataset.csv',usecols=[1,2,3])\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length          flower\n",
      "0             5.1     Iris-setosa\n",
      "1             4.9     Iris-setosa\n",
      "2             4.7     Iris-setosa\n",
      "3             4.6     Iris-setosa\n",
      "4             5.0     Iris-setosa\n",
      "..            ...             ...\n",
      "145           6.7  Iris-virginica\n",
      "146           6.3  Iris-virginica\n",
      "147           6.5  Iris-virginica\n",
      "148           6.2  Iris-virginica\n",
      "149           5.9  Iris-virginica\n",
      "\n",
      "[150 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "d=data[['sepal_length','flower']]\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([0, 4, 8]) \n",
    "s2 = pd.Series([1, 5, 9]) \n",
    "s3 = pd.Series([2, 6, 10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame([s1,s2,s3])\n",
    "df.columns=['x','y','z']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.to_csv(\"d://filter_iris.csv\")\n",
    "d.to_csv(\"d://iris.txt\",sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width          flower\n",
      "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
      "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
      "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
      "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
      "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
      "..            ...          ...           ...          ...             ...\n",
      "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_table(\"d://MLdataSet//iris_dataset.csv\",delimiter=',')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'ncols'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m csv\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43md://MLdataSet//iris_dataset.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mncols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m css\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'ncols'"
     ]
    }
   ],
   "source": [
    "csv=pd.read_csv(\"d://MLdataSet//iris_dataset.csv\",nrows=50)\n",
    "css.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>flower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width       flower\n",
       "14           5.8          4.0           1.2          0.2  Iris-setosa\n",
       "15           5.7          4.4           1.5          0.4  Iris-setosa\n",
       "18           5.7          3.8           1.7          0.3  Iris-setosa"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv[(csv['sepal_length']>5.5) & (csv['flower']=='Iris-setosa')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling CSV file\n",
    "- Syntax: csv_file = pandas.read_csv(fileName)\n",
    "- Above command will create a DataFrame and load data from file to it.\n",
    "\n",
    "#### What is CSV File\n",
    "###### A CSV is a comma separated values file which allows to store data in tabular format. That data includes numbers and text in plain text form. CSV is an extension of any file or spreadsheet .\n",
    "\n",
    "###### Advantages of CSV File\n",
    "1. Universally used\n",
    "2. Easy to read\n",
    "3. Easy to understand\n",
    "4. Quick to create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Missing Data\n",
    "import pandas as pds\n",
    "myfile=pds.read_table(\"d:\\\\MLDataSet\\\\myTips.csv\",delimiter=',',nrows=40)\n",
    "df=pds.DataFrame(myfile)\n",
    "#df.dropna(axis=1,inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
      "0             NaN          3.0           1.4          1.9     Setosa\n",
      "1             4.9          3.0           1.5          0.2     Setosa\n",
      "2             4.7          3.2           NaN          0.2     Setosa\n",
      "3             4.6          3.1           1.5          0.2     Setosa\n",
      "4             5.0          3.6           1.4          NaN     Setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "145           NaN          NaN           5.2          2.3  Virginica\n",
      "146           6.3          2.5           5.0          1.9  Virginica\n",
      "147           6.5          3.0           5.2          2.0  Virginica\n",
      "148           NaN          3.4           5.4          NaN  Virginica\n",
      "149           5.9          NaN           NaN          1.8  Virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pds\n",
    "df=pds.read_csv(\"d:\\\\MLDataSet\\\\iris.csv\")\n",
    "#df=pds.DataFrame(myfile)\n",
    "# Use fillna of complete Dataframe  \n",
    "# value function will be applied on every column \n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filling null with mean\n",
      "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
      "0         5.84964     3.000000      1.400000     1.900000     Setosa\n",
      "1         4.90000     3.000000      1.500000     0.200000     Setosa\n",
      "2         4.70000     3.200000      3.719858     0.200000     Setosa\n",
      "3         4.60000     3.100000      1.500000     0.200000     Setosa\n",
      "4         5.00000     3.600000      1.400000     1.182857     Setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "145       5.84964     3.060432      5.200000     2.300000  Virginica\n",
      "146       6.30000     2.500000      5.000000     1.900000  Virginica\n",
      "147       6.50000     3.000000      5.200000     2.000000  Virginica\n",
      "148       5.84964     3.400000      5.400000     1.182857  Virginica\n",
      "149       5.90000     3.060432      3.719858     1.800000  Virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pankaj Agarwal\\AppData\\Local\\Temp\\ipykernel_5928\\2455543134.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.fillna(value = df.mean(), inplace = True)\n"
     ]
    }
   ],
   "source": [
    "df.fillna(value = df.mean(), inplace = True) \n",
    "print(\"filling null with mean\")\n",
    "print(df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling value of one column \n",
    "df['Size'].fillna(value = df['Size'].mean(),inplace = True)\n",
    "print(\"for single column\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skipping rows with indexing\n",
    "#if you want to read only few lines then give required number of lines to nrows.\n",
    "import pandas as p\n",
    "myread=p.read_table(\"f:\\\\Tips.csv\",delimiter=',',skiprows=90,nrows=10)\n",
    "print(myread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to skip lines from bottom of file then give required number of lines to skipfooter.\n",
    "import pandas as p\n",
    "myread=p.read_table(\"f:\\\\Tips.csv\",delimiter=',',engine='python',skipfooter=75)\n",
    "print(myread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Row number(s) to use as the column names, and the start of the data occurs after the last row number given in header.\n",
    "import pandas as p\n",
    "myread=p.read_table(\"f:\\\\Tips.csv\",delimiter=',',index_col=0,header=[1,3,5])\n",
    "print(myread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "myCSV = pd.read_table(\"f:\\\\iris.csv\",delimiter=',',skiprows=4,index_col=0)\n",
    "#mydata=myCSV.columns=['SEPAL LENGTH','SEPAL WIDTH','PETAL LENGTH','SEPAL WIDTH','CLASS']\n",
    "print(myCSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(pd.Series([1., 2., 3.]) )\n",
    "print(pd.Series([1., 2., 3.], index=['a', 'b', 'c']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dt=pd.Series(['John','David','Smith','steve'],index=['a','b','c','d'])\n",
    "print(dt)\n",
    "nan=pd.Series([1,2,np.nan])\n",
    "print(nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[[1,2,3,4],[5,6,7,8]]\n",
    "print(data)\n",
    "DF=pd.DataFrame(data)\n",
    "print(DF)\n",
    "ar=np.array(DF)\n",
    "print(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'Name': [\"John\", \"Smith\"], 'Age': [30, 40]}\n",
    "mydata=pd.DataFrame(data=dic)\n",
    "print(mydata)\n",
    "mydata.head(1)\n",
    "mydata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('20300101', periods=6, freq='D')\n",
    "print('Day:', dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata[['Name','Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6.6</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>6.9</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.060432</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>Versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>3.719858</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1.182857</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1.182857</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.060432</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.719858</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>1.182857</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.060432</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.719858</td>\n",
       "      <td>1.182857</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.182857</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.060432</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.719858</td>\n",
       "      <td>1.182857</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.060432</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width     variety\n",
       "8             6.8     2.900000      1.400000     0.200000      Setosa\n",
       "50            7.0     3.200000      4.700000     1.400000  Versicolor\n",
       "51            6.4     3.200000      5.400000     1.500000  Versicolor\n",
       "52            6.9     3.100000      4.900000     1.500000  Versicolor\n",
       "54            6.5     2.800000      3.600000     1.500000  Versicolor\n",
       "56            6.3     3.300000      4.700000     1.600000  Versicolor\n",
       "58            6.6     2.900000      4.600000     1.300000  Versicolor\n",
       "63            6.1     2.900000      4.700000     1.400000  Versicolor\n",
       "65            6.7     3.100000      4.400000     1.400000  Versicolor\n",
       "68            6.2     2.200000      4.900000     1.500000  Versicolor\n",
       "69            6.9     2.500000      3.900000     1.100000  Versicolor\n",
       "71            6.1     3.800000      4.000000     1.300000  Versicolor\n",
       "72            6.3     2.500000      4.900000     1.500000  Versicolor\n",
       "73            6.1     2.800000      4.700000     1.200000  Versicolor\n",
       "74            6.4     2.900000      4.300000     1.300000  Versicolor\n",
       "75            6.6     3.000000      4.400000     1.400000  Versicolor\n",
       "76            6.8     2.800000      4.800000     1.400000  Versicolor\n",
       "77            6.7     3.000000      5.000000     1.700000  Versicolor\n",
       "82            6.8     2.700000      4.200000     1.200000  Versicolor\n",
       "86            6.7     3.100000      4.700000     1.500000  Versicolor\n",
       "87            6.3     2.300000      4.400000     1.300000  Versicolor\n",
       "91            6.1     3.000000      4.600000     1.400000  Versicolor\n",
       "97            6.2     3.060432      4.300000     1.300000  Versicolor\n",
       "100           6.3     3.300000      3.719858     2.500000   Virginica\n",
       "102           7.1     3.000000      5.900000     2.100000   Virginica\n",
       "104           6.5     3.000000      5.800000     2.200000   Virginica\n",
       "105           7.6     3.000000      6.600000     2.100000   Virginica\n",
       "107           7.3     2.900000      6.300000     1.800000   Virginica\n",
       "108           6.7     2.500000      5.800000     1.800000   Virginica\n",
       "110           6.5     3.200000      5.100000     2.000000   Virginica\n",
       "111           6.4     2.700000      5.300000     1.182857   Virginica\n",
       "112           6.8     3.000000      5.500000     2.100000   Virginica\n",
       "115           6.4     3.200000      5.300000     2.300000   Virginica\n",
       "116           6.5     3.000000      5.500000     1.800000   Virginica\n",
       "117           7.7     3.800000      6.700000     2.200000   Virginica\n",
       "118           7.7     2.600000      6.900000     2.300000   Virginica\n",
       "120           6.9     3.200000      5.700000     2.300000   Virginica\n",
       "122           7.7     2.800000      6.700000     2.000000   Virginica\n",
       "123           6.3     2.700000      4.900000     1.182857   Virginica\n",
       "124           6.7     3.060432      5.700000     2.100000   Virginica\n",
       "125           7.2     3.200000      3.719858     1.800000   Virginica\n",
       "127           6.1     3.000000      4.900000     1.800000   Virginica\n",
       "128           6.4     2.800000      5.600000     2.100000   Virginica\n",
       "129           7.2     3.000000      5.800000     1.600000   Virginica\n",
       "130           7.4     2.800000      6.100000     1.900000   Virginica\n",
       "131           7.9     3.800000      6.400000     2.000000   Virginica\n",
       "132           6.4     2.800000      5.600000     1.182857   Virginica\n",
       "134           6.1     3.060432      5.600000     1.400000   Virginica\n",
       "135           7.7     3.000000      3.719858     1.182857   Virginica\n",
       "137           6.4     3.100000      5.500000     1.182857   Virginica\n",
       "139           6.9     3.100000      5.400000     2.100000   Virginica\n",
       "141           6.9     3.060432      5.100000     2.300000   Virginica\n",
       "143           6.8     3.200000      3.719858     1.182857   Virginica\n",
       "144           6.7     3.060432      5.700000     2.500000   Virginica\n",
       "146           6.3     2.500000      5.000000     1.900000   Virginica\n",
       "147           6.5     3.000000      5.200000     2.000000   Virginica"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['sepal.length']>6.0) df['variety']=='Versicolor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal.length', 'sepal.width', 'petal.length', 'petal.width',\n",
       "       'variety'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.84964</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.90000</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.70000</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.60000</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>5.84964</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.30000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.50000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.84964</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.90000</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length    variety\n",
       "0         5.84964     Setosa\n",
       "1         4.90000     Setosa\n",
       "2         4.70000     Setosa\n",
       "3         4.60000     Setosa\n",
       "4         5.00000     Setosa\n",
       "..            ...        ...\n",
       "145       5.84964  Virginica\n",
       "146       6.30000  Virginica\n",
       "147       6.50000  Virginica\n",
       "148       5.84964  Virginica\n",
       "149       5.90000  Virginica\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,['sepal.length','variety']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loc function is used to select columns by names. \n",
    "#the values before the coma stand for the rows and after refer to the column\n",
    "mydata.loc[:,['Name','Age']]\n",
    "mydata.iloc[:,0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as p\n",
    "df=p.read_table(\"d:\\\\MLDataSet\\\\Tips.csv\",delimiter=',')\n",
    "print(df)\n",
    "#df.loc[5:,['Day','Time']]\n",
    "myday=df.loc[df['Day']=='Sun']\n",
    "print(myday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as p\n",
    "df=p.read_table(\"d:\\\\MLDataSet\\\\Tips.csv\",delimiter=',')\n",
    "#print(df)\n",
    "mytips=df.loc[df['Tips']>5]\n",
    "print(mytips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SINO  TotalBill  Tips Smoker  Day    Time  Size\n",
      "5      6      25.29  4.71     No  Sun  Dinner   4.0\n",
      "11    12      35.26  5.00     No  Sun  Dinner   4.0\n",
      "44    45      30.40  5.60     No  Sun  Dinner   4.0\n",
      "46    47      22.23  5.00     No  Sun  Dinner   2.0\n",
      "47    48      32.40  6.00     No  Sun  Dinner   4.0\n",
      "52    53      34.81  5.20     No  Sun  Dinner   4.0\n",
      "54    55      25.56  4.34     No  Sun  Dinner   4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as p\n",
    "df=p.read_table(\"d:\\\\MLDataSet\\\\Tips.csv\",delimiter=',')\n",
    "#print(df)\n",
    "mytips=df.loc[(df['Tips']>4) & (df['Day']=='Sun')]\n",
    "print(mytips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as p\n",
    "df=p.read_table(\"d:\\\\MLDataSet\\\\Tips.csv\",delimiter=',')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Smoker']=='Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['TotalBill']>30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['TotalBill']>30) & (df['Day']=='Sun')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['TotalBill']>30) | (df['Day']=='Sun')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalBill'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Append() Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"a\":[1, 2, 3, 4], \n",
    "                         \"b\":[5, 6, 7, 8]}) \n",
    "  \n",
    "# Creating the Second Dataframe using dictionary \n",
    "df2 = pd.DataFrame({\"a\":[1, 2, 3,4], \n",
    "                    \"b\":[5, 6, 7,10],\n",
    "                    \"C\":[10,20,30,40]}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df1,df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.append(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Join(), Merge(),Concat() Method\n",
    "-merge() for combining data on common columns or indices\n",
    "-join() for combining data on a key column or an index\n",
    "-concat() for combining DataFrames across rows or columns\n",
    "\n",
    "various forms of joins:\n",
    "\n",
    "1.inner\n",
    "2.outer\n",
    "3.left\n",
    "4.right"
   ]
  },
  {
   "attachments": {
    "join_diagram.webp": {
     "image/webp": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![join_diagram.webp](attachment:join_diagram.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d1 = {\n",
    "        'id': ['1', '2', '3', '4', '5'],\n",
    "        'Feature1': ['A', 'C', 'E', 'G', 'I'],\n",
    "        'Feature2': ['B', 'D', 'F', 'H', 'J']}\n",
    "data1 = pd.DataFrame(d1, columns = ['id', 'Feature1', 'Feature2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id Feature1 Feature2\n",
      "0  1        K        L\n",
      "1  2        M        N\n",
      "2  6        O        P\n",
      "3  7        Q        R\n",
      "4  8        S        T\n"
     ]
    }
   ],
   "source": [
    "d2 = {\n",
    "        'id': ['1', '2', '3', '7', '8'],\n",
    "        'Feature1': ['K', 'M', 'O', 'Q', 'S'],\n",
    "        'Feature2': ['L', 'N', 'P', 'R', 'T']}\n",
    "data2 = pd.DataFrame(d2, columns = ['id', 'Feature1', 'Feature2'])\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Feature3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Feature3\n",
       "0   1        12\n",
       "1   2        13\n",
       "2   3        14\n",
       "3   4        15\n",
       "4   5        16\n",
       "5   7        17\n",
       "6   8        15\n",
       "7   9        12\n",
       "8  10        13\n",
       "9  11        23"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3 = {\n",
    "        'id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n",
    "        'Feature3': [12, 13, 14, 15, 16, 17, 15, 12, 13, 23]}\n",
    "data3 = pd.DataFrame(d3, columns = ['id', 'Feature3'])\n",
    "\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the DataFrames along the row you can \n",
    "#use the concat() function in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>G</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>K</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Q</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id Feature1 Feature2\n",
       "0  1        A        B\n",
       "1  2        C        D\n",
       "2  3        E        F\n",
       "3  4        G        H\n",
       "4  5        I        J\n",
       "0  1        K        L\n",
       "1  2        M        N\n",
       "2  6        O        P\n",
       "3  7        Q        R\n",
       "4  8        S        T"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_row = pd.concat([data1, data2])\n",
    "\n",
    "df_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the row labels seem to be wrong! If you want the row labels to adjust automatically according to the join, you will have to set the argument ignore_index as True while calling the concat() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_row_reindex = pd.concat([data1, data2], ignore_index=True)\n",
    "\n",
    "df_row_reindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas also provides you with an option to label the DataFrames, after the concatenation, with a key so that you may know which data came from which DataFrame. You can achieve the same by passing additional argument keys specifying the label names of the DataFrames in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [data1,data2]\n",
    "df_keys = pd.concat(frames, keys=['x', 'y'])\n",
    "\n",
    "df_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keys.loc['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To concatenate DataFrames along column, you can specify the axis parameter as 1 :\n",
    "df_col = pd.concat([data1,data2], axis=1)\n",
    "\n",
    "df_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge DataFrames\n",
    "Another ubiquitous operation related to DataFrames is the merging operation. Two DataFrames might hold different kinds of information about the same entity and linked by some common feature/column. To join these DataFrames, pandas provides multiple functions like concat(), merge() , join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_row = pd.concat([df1, df2])\n",
    "\n",
    "df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>G</td>\n",
       "      <td>H</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I</td>\n",
       "      <td>J</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id Feature1 Feature2  Feature3\n",
       "0  1        A        B        12\n",
       "1  2        C        D        13\n",
       "2  3        E        F        14\n",
       "3  4        G        H        15\n",
       "4  5        I        J        16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_col = pd.merge(data1, data3, on='id')\n",
    "df_merge_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might happen that the column on which you want to merge the DataFrames have different names . For such merges, you will have to specify the arguments left_on as the left DataFrame name and right_on as the right DataFrame name, like :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>G</td>\n",
       "      <td>H</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I</td>\n",
       "      <td>J</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id Feature1 Feature2  Feature3\n",
       "0  1        A        B        12\n",
       "1  2        C        D        13\n",
       "2  3        E        F        14\n",
       "3  4        G        H        15\n",
       "4  5        I        J        16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_difkey = pd.merge(data1, data3, left_on='id', right_on='id')\n",
    "df_merge_difkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join DataFrames\n",
    "\n",
    "-Inner Join or Natural join: To keep only rows that match from the data frames, specify the argument how=‘inner’.\n",
    "\n",
    "-Outer Join or Full outer join:To keep all rows from both data frames, specify how=‘outer’.\n",
    "\n",
    "-Left Join or Left outer join:To include all the rows of your data frame x and only those from y that match, specify how=‘left’.\n",
    "\n",
    "-Right Join or Right outer join:To include all the rows of your data frame y and only those from x that match, specify how=‘right’."
   ]
  },
  {
   "attachments": {
    "join-or-merge-in-python-pandas-1.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![join-or-merge-in-python-pandas-1.png](attachment:join-or-merge-in-python-pandas-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Outer Join\n",
    "The FULL OUTER JOIN combines the results of both the left and the right outer joins. The joined DataFrame will contain all records from both the DataFrames and fill in NaNs for missing matches on either side. You can perform a full outer join by specifying the how argument as outer in the merge() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Feature1_x</th>\n",
       "      <th>Feature2_x</th>\n",
       "      <th>Feature1_y</th>\n",
       "      <th>Feature2_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>K</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>G</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I</td>\n",
       "      <td>J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id Feature1_x Feature2_x Feature1_y Feature2_y\n",
       "0  1          A          B          K          L\n",
       "1  2          C          D          M          N\n",
       "2  3          E          F        NaN        NaN\n",
       "3  4          G          H        NaN        NaN\n",
       "4  5          I          J        NaN        NaN\n",
       "5  6        NaN        NaN          O          P\n",
       "6  7        NaN        NaN          Q          R\n",
       "7  8        NaN        NaN          S          T"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outer=pd.merge(data1,data2,how ='outer',on='id')\n",
    "df_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    " \n",
    "\n",
    "# data frame 1\n",
    "\n",
    "d1 = {'Customer_id':pd.Series([1,2,3,4,5,6]),\n",
    "  'Product':pd.Series(['Oven','Oven','Oven','Television','Television','Television'])}\n",
    "\n",
    "df1 = pd.DataFrame(d1)\n",
    "\n",
    "# data frame 2\n",
    "\n",
    "d2 = {'Customer_id':pd.Series([2,4,6,7,8]),\n",
    "    'State':pd.Series(['California','California','Texas','New York','Indiana'])}\n",
    "df2 = pd.DataFrame(d2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Oven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Television</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_id     Product\n",
       "0            1        Oven\n",
       "1            2        Oven\n",
       "2            3        Oven\n",
       "3            4  Television\n",
       "4            5  Television\n",
       "5            6  Television"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_id</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Indiana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_id       State\n",
       "0            2  California\n",
       "1            4  California\n",
       "2            6       Texas\n",
       "3            7    New York\n",
       "4            8     Indiana"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df1,df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_id</th>\n",
       "      <th>Product</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Oven</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Television</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Television</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Customer_id     Product       State\n",
       "0            2        Oven  California\n",
       "1            4  Television  California\n",
       "2            6  Television       Texas"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inner join in python pandas\n",
    "inner_join_df= pd.merge(df1, df2, on='Customer_id', how='inner')\n",
    "inner_join_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outer join in pandas:\n",
    "#Returns all rows from both tables, join records from the left \n",
    "#which have matching keys in the right table.When there is no \n",
    "#Matching from any table NaN will be returned\n",
    "outer_join_df=pd.merge(df1, df2, on='Customer_id', how='outer')\n",
    "outer_join_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Left outer Join or Left join pandas:\n",
    "#Return all rows from the left table, and any rows with \n",
    "#matching keys from the right table.When there is no Matching from\n",
    "#right table NaN will be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_join_df= pd.merge(df1, df2, on='Customer_id', how='left')\n",
    "left_join_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Right outer join or Right Join pandas\n",
    "#Return all rows from the right table, and any rows with \n",
    "#matching keys from the left table.\n",
    "right_join_df= pd.merge(df1, df2, on='Customer_id', how='right')\n",
    "right_join_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loc vs iloc\n",
    "You can use iloc in Python for selection. It is integer-location based and helps you select by the position. So, if you want to find the row with index 5, iloc will show you the fifth row of the data frame irrespective of its name or label. \n",
    "\n",
    "loc\n",
    "use loc to select data by the label.\n",
    "\n",
    "You can use loc in Pandas to access multiple rows and columns by using labels; however, you can use it with a boolean array as well. \n",
    "\n",
    "If you use loc to find a row with index 5, you won’t get the fifth row with it. Instead, you will only get the row which has the name ‘5’. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"selecting row with specific column\")\n",
    "print(df.loc[3,'Day'])\n",
    "\n",
    "print(\"selecting specific rows and columns\")\n",
    "print(df.loc[1:10,['Day','Size']])\n",
    "\n",
    "print(\"selecting row with specific index\")\n",
    "print(df.iloc[3])\n",
    "\n",
    "print(\"selecting rows <= specific index\")\n",
    "print(df.loc[:3])\n",
    "\n",
    "print(\"selecting all rows and specific col\")\n",
    "print(df.iloc[:,1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Rows from Pandas DataFrame with conditions\n",
    "from pandas import DataFrame\n",
    "\n",
    "boxes = {'Color': ['Green','Green','Green','Blue','Blue','Red','Red','Red'],\n",
    "         'Shape': ['Rectangle','Rectangle','Square','Rectangle','Square','Square','Square','Rectangle'],\n",
    "         'Price': [10,15,5,5,10,15,15,5]\n",
    "        }\n",
    "\n",
    "df = DataFrame(boxes, columns= ['Color','Shape','Price'])\n",
    "\n",
    "select_color = df.loc[df['Color'] == 'Green']\n",
    "print (select_color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.fdic.gov/bank/individual/failed/banklist.html'\n",
    "u = pd.read_html(url)\n",
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading/Writing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('F:\\\\iris.csv','rt')as f:\n",
    "  data = csv.reader(f)\n",
    "  for row in data:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "with open('F:\\\\iris.csv','rt')as f:\n",
    "    data = csv.reader(f)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.DictReader(open('F:\\\\iris.csv'))\n",
    "for raw in reader:\n",
    "    print(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('F:\\\\csvWrite.csv', mode='w') as file:\n",
    "    writer = csv.writer(file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    #way to write to csv file\n",
    "    writer.writerow(['Programming language', 'Designed by', 'Appeared', 'Extension'])\n",
    "    writer.writerow(['Python', 'Guido van Rossum', '1991', '.py'])\n",
    "    writer.writerow(['Java', 'James Gosling', '1995', '.java'])\n",
    "    writer.writerow(['C++', 'Bjarne Stroustrup', '1985', '.cpp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "myCSV = pd.read_txt(\"f:\\\\iris.csv\")\n",
    "mydata=myCSV.columns=['SEPAL LENGTH','SEPAL WIDTH','PETAL LENGTH','SEPAL WIDTH','CLASS']\n",
    "print(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "C = {'Programming language': ['Python','Java', 'C++'],\n",
    "        'Designed by': ['Guido van Rossum', 'James Gosling', 'Bjarne Stroustrup'],\n",
    "        'Appeared': ['1991', '1995', '1985'],\n",
    "        'Extension': ['.py', '.java', '.cpp'],\n",
    "    }\n",
    "df = DataFrame(C,columns= ['Programming language', 'Designed by', 'Appeared', 'Extension'])\n",
    "export_csv = df.to_csv (r'F:\\\\pandaresult.csv', index = None, header=True) \n",
    "# here you have to write path, where result file will be stored\n",
    "print (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('F:\\\\test.txt', 'r')\n",
    "# This will print every line one by one in the file\n",
    "#for each in file:\n",
    " #   print (each)\n",
    "print(file.read(40))\n",
    "\n",
    "file = open('F:\\\\TestW.txt', 'w')\n",
    "file.write(\"This is the write command\")\n",
    "file.write(\"\\n It allows us to write in a particular file\")\n",
    "file.close()\n",
    "\n",
    "\n",
    "file = open('F:\\\\test.txt', 'a')\n",
    "file.write(\"This is the test of append mode\")\n",
    "file.write(\"\\n we are appending the contents of a file\")\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urldata = pd.read_csv(\"http://winterolympicsmedals.com/medals.csv\")\n",
    "print(urldata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#import xlsxwriter \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "myTAG=pd.read_excel(\"F:\\\\TAGGINGDATA.xlsx\",sheet_name='SHEET8',nrows=10)\n",
    "print(myTAG)\n",
    "pole=myTAG['POLE NO'].value_counts().idxmax()\n",
    "area=myTAG['AREA'].value_counts().idxmax()\n",
    "print(pole,area)\n",
    "myarea=myTAG['AREA'].value_counts()[:10].index.tolist()\n",
    "print(myarea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myExcel=pd.read_excel(\"F:\\\\BILLING.xlsx\",sheet_name='2012')\n",
    "#print(myExcel['E Tax'])\n",
    "print(myExcel.columns.ravel())\n",
    "print(myExcel['Normal Unit'].tolist())\n",
    "normalunit=myExcel['Normal Unit'].tolist()\n",
    "print(normalunit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as p\n",
    "myex=pd.read_excel(\"f:\\\\Tips1.xlsx\")\n",
    "mydf=pd.DataFrame(myex)\n",
    "print(mydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "myfile=pd.read_csv(\"f:\\\\tips.csv\")\n",
    "df=pd.DataFrame(myfile)\n",
    "#print(df)\n",
    "df1=pd.DataFrame(myfile, columns= ['Time', 'TotalBill', 'Tips'] )\n",
    "df2=myfile[['Time', 'TotalBill', 'Tips']]\n",
    "df3=myfile.iloc[:,0:2]\n",
    "df4=myfile.loc[:, ['Time', 'TotalBill', 'Tips'] ]\n",
    "#print(df1)\n",
    "#print(df2)\n",
    "#print(df3)\n",
    "#print(df4)\n",
    "myex=pd.read_excel(\"f:\\\\Tips1.xlsx\")\n",
    "data=pd.DataFrame(myex)\n",
    "data1=pd.DataFrame(myex)\n",
    "data2 = pd.merge(df, data1, how='left')\n",
    "#print(data2)\n",
    "data3 = data2.copy()\n",
    "#print(data3)\n",
    "#data3.groupby('Day')[['Tips']].aggregate(sum)\n",
    "#data3.groupby('Gender')['Time'].aggregate(sum)\n",
    "data3.groupby(['Gender', 'Time'])['Time'].count().unstack()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "x=[5,4,3,2,1]\n",
    "y=[7,8,9]\n",
    "z=[x,y]\n",
    "a=copy.deepcopy(z)\n",
    "b=copy.copy(z)\n",
    "x[2]=6\n",
    "print('a=',a,'b=',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#mydata=pd.read_excel(\"f:\\\\BILLING.xlsx\",sheet_name='2012')\n",
    "myCSV = pd.read_csv(\"f:\\\\iris.csv\")\n",
    "myCSV.columns=['SEPAL LENGTH','SEPAL WIDTH','PETAL LENGTH','SEPAL WIDTH','CLASS']\n",
    "mycols = pd.read_csv(\"f:\\\\iris.csv\",nrows=10,usecols=(1,2,4))\n",
    "print(mycols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to Plot a DataFrame using Pandas\n",
    "from pandas import DataFrame\n",
    "   \n",
    "Data = {'Unemployment_Rate': [6.1,5.8,5.7,5.7,5.8,5.6,5.5,5.3,5.2,5.2],\n",
    "        'Stock_Index_Price': [1500,1520,1525,1523,1515,1540,1545,1560,1555,1565]\n",
    "       }\n",
    "  \n",
    "df = DataFrame(Data,columns=['Unemployment_Rate','Stock_Index_Price'])\n",
    "print (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#mydata=pd.read_excel(\"f:\\\\BILLING.xlsx\",sheet_name='2012')\n",
    "myCSV = pd.read_csv(\"f:\\\\iris.csv\")\n",
    "myCSV.columns=['SEPAL LENGTH','SEPAL WIDTH','PETAL LENGTH','SEPAL WIDTH','CLASS']\n",
    "mycols = pd.read_csv(\"f:\\\\iris.csv\",nrows=20,usecols=(1,2,4))\n",
    "#print(mycols)\n",
    "df=pd.DataFrame(mycols)\n",
    "#print(df)\n",
    "mySelect = df.loc[df['sepal.width'] >= 3.5]\n",
    "print (mySelect)\n",
    "mySelect1 = df.loc[df['variety'] == 'Setosa']\n",
    "print (mySelect1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The groupby method allows us to group together the data based off any row or column\n",
    "import pandas as pds\n",
    "myfile=pds.read_table(\"f:\\\\myTips.csv\",delimiter=',',nrows=60)\n",
    "df=pds.DataFrame(myfile)\n",
    "df.groupby(['Day']).max()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the DataFrame using pandas\n",
    "from pandas import DataFrame\n",
    "   \n",
    "Data = {'Unemployment_Rate': [6.1,5.8,5.7,5.7,5.8,5.6,5.5,5.3,5.2,5.2],\n",
    "        'Stock_Index_Price': [1500,1520,1525,1523,1515,1540,1545,1560,1555,1565]\n",
    "       }\n",
    "  \n",
    "df = DataFrame(Data,columns=['Unemployment_Rate','Stock_Index_Price'])\n",
    "df.plot(x ='Unemployment_Rate', y='Stock_Index_Price', kind = 'scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a Line chart using pandas\n",
    "from pandas import DataFrame\n",
    "   \n",
    "Data = {'Year': [1920,1930,1940,1950,1960,1970,1980,1990,2000,2010],\n",
    "        'Unemployment_Rate': [9.8,12,8,7.2,6.9,7,6.5,6.2,5.5,6.3]\n",
    "       }\n",
    "  \n",
    "df = DataFrame(Data,columns=['Year','Unemployment_Rate'])\n",
    "print (df)\n",
    "df.plot(x ='Year', y='Unemployment_Rate', kind = 'line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a bar chart using pandas\n",
    "from pandas import DataFrame\n",
    "   \n",
    "Data = {'Country': ['USA','Canada','Germany','UK','France'],\n",
    "        'GDP_Per_Capita': [45000,42000,52000,49000,47000]\n",
    "       }\n",
    "  \n",
    "df = DataFrame(Data,columns=['Country','GDP_Per_Capita'])\n",
    "df.plot(x ='Country', y='GDP_Per_Capita', kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a pie chart using pandas\n",
    "from pandas import DataFrame\n",
    "\n",
    "Data = {'Tasks': [300,500,700]}\n",
    "df = DataFrame(Data,columns=['Tasks'],index = ['Tasks Pending','Tasks Ongoing','Tasks Completed'])\n",
    "\n",
    "df.plot.pie(y='Tasks',figsize=(5, 5),autopct='%1.1f%%', startangle=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SINO</th>\n",
       "      <th>TotalBill</th>\n",
       "      <th>Tips</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>40.17</td>\n",
       "      <td>4.73</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>27.28</td>\n",
       "      <td>4.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fri</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>21.01</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>25.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SINO  TotalBill  Tips Smoker  Day    Time  Size\n",
       "0      1      16.99  1.01     No  Sun  Dinner   2.0\n",
       "1      2      10.34  1.66     No  Sun  Dinner   3.0\n",
       "2      3        NaN  3.50     No  Sun  Dinner   3.0\n",
       "3      4      23.68  3.31     No  NaN  Dinner   2.0\n",
       "4      5      24.59  3.61     No  Sun  Dinner   NaN\n",
       "..   ...        ...   ...    ...  ...     ...   ...\n",
       "95    96      40.17  4.73    Yes  Fri     NaN   4.0\n",
       "96    97      27.28  4.00    NaN  Fri  Dinner   2.0\n",
       "97    98        NaN  1.50    Yes  Fri  Dinner   NaN\n",
       "98    99      21.01  3.00    Yes  Fri     NaN   2.0\n",
       "99   100      25.10   NaN    NaN  NaN   Lunch   2.0\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pds\n",
    "myfile=pds.read_table(\"d:\\\\MLDataSet\\\\myTips.csv\",delimiter=',')\n",
    "df=pds.DataFrame(myfile)\n",
    "#df.head()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SINO</th>\n",
       "      <th>TotalBill</th>\n",
       "      <th>Tips</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Time</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fri</th>\n",
       "      <td>91</td>\n",
       "      <td>28.97</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sat</th>\n",
       "      <td>20</td>\n",
       "      <td>20.65</td>\n",
       "      <td>3.35</td>\n",
       "      <td>No</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sun</th>\n",
       "      <td>1</td>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>No</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thur</th>\n",
       "      <td>78</td>\n",
       "      <td>27.20</td>\n",
       "      <td>4.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Lunch</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SINO  TotalBill  Tips Smoker    Time  Size\n",
       "Day                                             \n",
       "Fri     91      28.97  3.00    Yes  Dinner   2.0\n",
       "Sat     20      20.65  3.35     No  Dinner   3.0\n",
       "Sun      1      16.99  1.01     No  Dinner   2.0\n",
       "Thur    78      27.20  4.00     No   Lunch   4.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp=df.groupby('Day')\n",
    "# print the first entries in all the groups formed. \n",
    "grp.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SINO</th>\n",
       "      <th>TotalBill</th>\n",
       "      <th>Tips</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>20.65</td>\n",
       "      <td>3.35</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>17.92</td>\n",
       "      <td>4.08</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>20.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>15.77</td>\n",
       "      <td>2.23</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>19.82</td>\n",
       "      <td>3.18</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>17.81</td>\n",
       "      <td>2.34</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>13.37</td>\n",
       "      <td>2.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>21.70</td>\n",
       "      <td>4.30</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>19.65</td>\n",
       "      <td>3.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>18.35</td>\n",
       "      <td>2.50</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>15.06</td>\n",
       "      <td>3.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.45</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>17.78</td>\n",
       "      <td>3.27</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>24.06</td>\n",
       "      <td>3.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>16.31</td>\n",
       "      <td>2.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>18.69</td>\n",
       "      <td>2.31</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>16.04</td>\n",
       "      <td>2.24</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>38.01</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>26.41</td>\n",
       "      <td>1.50</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>11.24</td>\n",
       "      <td>1.76</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>48.27</td>\n",
       "      <td>6.73</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>20.29</td>\n",
       "      <td>3.21</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>13.81</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>11.02</td>\n",
       "      <td>1.98</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>18.29</td>\n",
       "      <td>3.76</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>65</td>\n",
       "      <td>17.59</td>\n",
       "      <td>2.64</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>67</td>\n",
       "      <td>16.45</td>\n",
       "      <td>2.47</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>68</td>\n",
       "      <td>3.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>20.23</td>\n",
       "      <td>2.01</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>15.01</td>\n",
       "      <td>2.09</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>71</td>\n",
       "      <td>12.02</td>\n",
       "      <td>1.97</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>17.07</td>\n",
       "      <td>3.00</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>25.28</td>\n",
       "      <td>5.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>14.73</td>\n",
       "      <td>2.20</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>10.51</td>\n",
       "      <td>1.25</td>\n",
       "      <td>No</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>17.92</td>\n",
       "      <td>3.08</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sat</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SINO  TotalBill  Tips Smoker  Day    Time  Size\n",
       "19    20      20.65  3.35     No  Sat  Dinner   3.0\n",
       "20    21      17.92  4.08     No  Sat  Dinner   2.0\n",
       "21    22      20.29   NaN     No  Sat  Dinner   2.0\n",
       "22    23      15.77  2.23     No  Sat  Dinner   2.0\n",
       "24    25      19.82  3.18     No  Sat  Dinner   2.0\n",
       "25    26      17.81  2.34     No  Sat  Dinner   4.0\n",
       "26    27      13.37  2.00     No  Sat  Dinner   2.0\n",
       "27    28        NaN   NaN     No  Sat  Dinner   2.0\n",
       "28    29      21.70  4.30     No  Sat  Dinner   2.0\n",
       "29    30      19.65  3.00     No  Sat  Dinner   2.0\n",
       "31    32      18.35  2.50     No  Sat  Dinner   4.0\n",
       "32    33      15.06  3.00     No  Sat  Dinner   2.0\n",
       "33    34        NaN  2.45     No  Sat  Dinner   4.0\n",
       "34    35      17.78  3.27     No  Sat  Dinner   2.0\n",
       "35    36      24.06  3.60    NaN  Sat  Dinner   3.0\n",
       "36    37      16.31  2.00     No  Sat  Dinner   3.0\n",
       "38    39      18.69  2.31     No  Sat  Dinner   3.0\n",
       "40    41      16.04  2.24     No  Sat  Dinner   3.0\n",
       "56    57      38.01  3.00    Yes  Sat  Dinner   4.0\n",
       "57    58      26.41  1.50     No  Sat  Dinner   2.0\n",
       "58    59      11.24  1.76    Yes  Sat  Dinner   2.0\n",
       "59    60      48.27  6.73     No  Sat  Dinner   NaN\n",
       "60    61      20.29  3.21    Yes  Sat     NaN   2.0\n",
       "61    62      13.81  2.00    Yes  Sat  Dinner   2.0\n",
       "62    63      11.02  1.98    Yes  Sat  Dinner   2.0\n",
       "63    64      18.29  3.76    Yes  Sat  Dinner   4.0\n",
       "64    65      17.59  2.64     No  Sat  Dinner   3.0\n",
       "65    66        NaN  3.15    NaN  Sat  Dinner   3.0\n",
       "66    67      16.45  2.47     No  Sat  Dinner   2.0\n",
       "67    68       3.07  1.00    Yes  Sat  Dinner   1.0\n",
       "68    69      20.23  2.01     No  Sat  Dinner   NaN\n",
       "69    70      15.01  2.09    Yes  Sat  Dinner   2.0\n",
       "70    71      12.02  1.97     No  Sat  Dinner   2.0\n",
       "71    72      17.07  3.00     No  Sat  Dinner   3.0\n",
       "72    73        NaN  3.14    Yes  Sat  Dinner   2.0\n",
       "73    74      25.28  5.00    Yes  Sat  Dinner   NaN\n",
       "74    75      14.73  2.20     No  Sat  Dinner   2.0\n",
       "75    76      10.51  1.25     No  Sat  Dinner   2.0\n",
       "76    77      17.92  3.08    Yes  Sat  Dinner   2.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding all values in one group\n",
    "grp.get_group('Sat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning with Pandas\n",
    "According to IBM Data Analytics you can expect to spend up to 80% of your time cleaning data.\n",
    "\n",
    "Data Cleaning activities -Missing Data -Irregular Data (Outliers) -Unnecessary Data — Repetitive Data, Duplicates and more -Inconsistent Data — Capitalization, Addresses and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SINO  TotalBill  Tips Smoker  Day    Time  Size\n",
      "0     1      16.99  1.01     No  Sun  Dinner   2.0\n",
      "1     2      10.34  1.66     No  Sun  Dinner   3.0\n",
      "2     3        NaN  3.50     No  Sun  Dinner   3.0\n",
      "3     4      23.68  3.31     No  NaN  Dinner   2.0\n",
      "4     5      24.59  3.61     No  Sun  Dinner   NaN\n",
      "   SINO  TotalBill  Tips Smoker  Day    Time\n",
      "0     1      16.99  1.01     No  Sun  Dinner\n",
      "1     2      10.34  1.66     No  Sun  Dinner\n",
      "2     3        NaN  3.50     No  Sun  Dinner\n",
      "3     4      23.68  3.31     No  NaN  Dinner\n",
      "4     5      24.59  3.61     No  Sun  Dinner\n"
     ]
    }
   ],
   "source": [
    "#Drop Columns\n",
    "import pandas as pds\n",
    "myfile=pds.read_table(\"d:\\\\MLDataSet\\\\myTips.csv\",delimiter=',')\n",
    "df=pds.DataFrame(myfile)\n",
    "print(df.head())\n",
    "noSize=df.drop(columns='Size')\n",
    "print(noSize.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SINO  TotalBill  Tips Smoker  Day\n",
      "0      1      16.99  1.01     No  Sun\n",
      "1      2      10.34  1.66     No  Sun\n",
      "2      3        NaN  3.50     No  Sun\n",
      "3      4      23.68  3.31     No  NaN\n",
      "4      5      24.59  3.61     No  Sun\n",
      "..   ...        ...   ...    ...  ...\n",
      "95    96      40.17  4.73    Yes  Fri\n",
      "96    97      27.28  4.00    NaN  Fri\n",
      "97    98        NaN  1.50    Yes  Fri\n",
      "98    99      21.01  3.00    Yes  Fri\n",
      "99   100      25.10   NaN    NaN  NaN\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Drop Multiple Columns\n",
    "multiDrop=df.drop(columns=['Time','Size'])\n",
    "print(multiDrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SINO  TotalBill  Tips Smoker  Day    Time  Size\n",
      "0      1      16.99  1.01     No  Sun  Dinner   2.0\n",
      "2      3        NaN  3.50     No  Sun  Dinner   3.0\n",
      "3      4      23.68  3.31     No  NaN  Dinner   2.0\n",
      "4      5      24.59  3.61     No  Sun  Dinner   NaN\n",
      "5      6      25.29  4.71     No  Sun  Dinner   4.0\n",
      "..   ...        ...   ...    ...  ...     ...   ...\n",
      "95    96      40.17  4.73    Yes  Fri     NaN   4.0\n",
      "96    97      27.28  4.00    NaN  Fri  Dinner   2.0\n",
      "97    98        NaN  1.50    Yes  Fri  Dinner   NaN\n",
      "98    99      21.01  3.00    Yes  Fri     NaN   2.0\n",
      "99   100      25.10   NaN    NaN  NaN   Lunch   2.0\n",
      "\n",
      "[99 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#Drop Rows\n",
    "oneRow=df.drop(index=1)\n",
    "print(oneRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SINO  TotalBill  Tips Smoker  Day    Time  Size\n",
      "3      4      23.68  3.31     No  NaN  Dinner   2.0\n",
      "4      5      24.59  3.61     No  Sun  Dinner   NaN\n",
      "5      6      25.29  4.71     No  Sun  Dinner   4.0\n",
      "6      7       8.77  2.00     No  Sun  Dinner   NaN\n",
      "7      8        NaN  3.12     No  Sun  Dinner   4.0\n",
      "..   ...        ...   ...    ...  ...     ...   ...\n",
      "95    96      40.17  4.73    Yes  Fri     NaN   4.0\n",
      "96    97      27.28  4.00    NaN  Fri  Dinner   2.0\n",
      "97    98        NaN  1.50    Yes  Fri  Dinner   NaN\n",
      "98    99      21.01  3.00    Yes  Fri     NaN   2.0\n",
      "99   100      25.10   NaN    NaN  NaN   Lunch   2.0\n",
      "\n",
      "[97 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#Drop Multiple Rows\n",
    "multiRow=df.drop(index=[0,1,2])\n",
    "#multiRow=df.drop(index=[0:10])\n",
    "print(multiRow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': ['Pankaj', 'sapna', 'Parth', 'Hansika'], 'ID': [1, 2, 3, 4], 'Role': ['Professor', 'Asst. Professor', 'CEO', 'Director']}\n",
      "      Name  ID             Role\n",
      "0   Pankaj   1        Professor\n",
      "1    sapna   2  Asst. Professor\n",
      "2    Parth   3              CEO\n",
      "3  Hansika   4         Director\n",
      "      Name             Role\n",
      "0   Pankaj        Professor\n",
      "1    sapna  Asst. Professor\n",
      "2    Parth              CEO\n",
      "3  Hansika         Director\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d1 = {'Name': ['Pankaj', 'sapna', 'Parth','Hansika'], 'ID': [1, 2, 3,4], 'Role': ['Professor', 'Asst. Professor', 'CEO','Director']}\n",
    "print(d1)\n",
    "dr=pd.DataFrame(d1)\n",
    "print(dr)\n",
    "dr.drop(columns=['ID'],inplace=True)\n",
    "print(dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name      Role\n",
      "2    Parth       CEO\n",
      "3  Hansika  Director\n"
     ]
    }
   ],
   "source": [
    "dropRows=dr.drop(labels=[0,1],axis=0)\n",
    "print(dropRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name\n",
      "0   Pankaj\n",
      "1    sapna\n",
      "2    Parth\n",
      "3  Hansika\n"
     ]
    }
   ],
   "source": [
    "dropCols=dr.drop(labels=['Role'],axis=1)\n",
    "print(dropCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name             Role\n",
      "0   Pankaj        Professor\n",
      "1    sapna  Asst. Professor\n",
      "2    Parth              CEO\n",
      "3  Hansika         Director\n"
     ]
    }
   ],
   "source": [
    "#We can suppress this error by specifying errors='ignore' \n",
    "#in the drop() function call.\n",
    "dropErr=dr.drop(labels=['XYZ'],axis=1,errors='ignore')\n",
    "print(dropErr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop Duplicates\n",
    "Pandas drop_duplicates() function removes duplicate rows from the DataFrame.\n",
    "\n",
    "Its syntax is:\n",
    "\n",
    "drop_duplicates(self, subset=None, keep=\"first\", inplace=False)\n",
    "\n",
    "subset: column label or sequence of labels to consider for identifying duplicate rows. By default, all the columns are used to find the duplicate rows.\n",
    "\n",
    "keep: allowed values are {‘first’, ‘last’, False}, default ‘first’. If ‘first’, duplicate rows except the first one is deleted. If ‘last’, duplicate rows except the last one is deleted. If False, all the duplicate rows are deleted.\n",
    "\n",
    "inplace: if True, the source DataFrame is changed and None is returned. By default, source DataFrame remains unchanged and a new DataFrame instance is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source DataFrame:\n",
      "    A  B  C  D\n",
      "0  1  2  3  3\n",
      "1  1  2  3  3\n",
      "2  1  2  4  4\n",
      "3  2  3  5  5\n",
      "Result dataframe\n",
      "    A  B  C  D\n",
      "0  1  2  3  3\n",
      "2  1  2  4  4\n",
      "3  2  3  5  5\n"
     ]
    }
   ],
   "source": [
    "#Drop Duplicate Rows Keeping the First One\n",
    "import pandas as pd\n",
    "\n",
    "d1 = {'A': [1, 1, 1, 2], 'B': [2, 2, 2, 3], 'C': [3, 3, 4, 5],'D': [3, 3, 4, 5]}\n",
    "\n",
    "source_df = pd.DataFrame(d1)\n",
    "print('Source DataFrame:\\n', source_df)\n",
    "\n",
    "# keep first duplicate row\n",
    "result_df = source_df.drop_duplicates()\n",
    "print('Result dataframe\\n',result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result dataframe\n",
      "    A  B  C  D\n",
      "1  1  2  3  3\n",
      "2  1  2  4  4\n",
      "3  2  3  5  5\n"
     ]
    }
   ],
   "source": [
    "#Drop Duplicates and Keep Last Row\n",
    "\n",
    "result_df = source_df.drop_duplicates(keep='last')\n",
    "print('Result dataframe\\n',result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source DataFrame:\n",
      "    A  B  C  D\n",
      "0  1  2  3  3\n",
      "1  1  2  3  3\n",
      "2  1  2  4  4\n",
      "3  2  3  5  5\n",
      "Result dataframe\n",
      "    A  B  C  D\n",
      "2  1  2  4  4\n",
      "3  2  3  5  5\n"
     ]
    }
   ],
   "source": [
    "#Delete All Duplicate Rows from DataFrame\n",
    "print('Source DataFrame:\\n', source_df)\n",
    "result_df = source_df.drop_duplicates(keep=False)\n",
    "print('Result dataframe\\n',result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source DataFrame:\n",
      "    A  B  C  D\n",
      "0  1  2  3  3\n",
      "1  1  2  3  3\n",
      "2  1  2  4  4\n",
      "3  2  3  5  5\n",
      "Result dataframe\n",
      "    A  B  C  D\n",
      "0  1  2  3  3\n",
      "3  2  3  5  5\n"
     ]
    }
   ],
   "source": [
    "#Identify Duplicate Rows based on Specific Columns\n",
    "print('Source DataFrame:\\n', source_df)\n",
    "result_df = source_df.drop_duplicates(subset=['A','B'])\n",
    "print('Result dataframe\\n',result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source DataFrame:\n",
      "    A  B  C  D\n",
      "0  1  2  3  3\n",
      "1  1  2  3  3\n",
      "2  1  2  4  4\n",
      "3  2  3  5  5\n",
      "Result dataframe\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "print('Source DataFrame:\\n', source_df)\n",
    "dupRows=source_df.drop_duplicates(inplace=True)\n",
    "print('Result dataframe\\n',dupRows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Pandas String and Regular Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to convert all the string values to upper, lower cases in a given pandas series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original series:\n",
      "0         X\n",
      "1         Y\n",
      "2         Z\n",
      "3      Aaba\n",
      "4      Baca\n",
      "5       NaN\n",
      "6      CABA\n",
      "7      None\n",
      "8      bird\n",
      "9     horse\n",
      "10      dog\n",
      "dtype: object\n",
      "\n",
      "Convert all string values of the said Series to upper case:\n",
      "0         X\n",
      "1         Y\n",
      "2         Z\n",
      "3      AABA\n",
      "4      BACA\n",
      "5       NaN\n",
      "6      CABA\n",
      "7      None\n",
      "8      BIRD\n",
      "9     HORSE\n",
      "10      DOG\n",
      "dtype: object\n",
      "\n",
      "Convert all string values of the said Series to lower case:\n",
      "0         x\n",
      "1         y\n",
      "2         z\n",
      "3      aaba\n",
      "4      baca\n",
      "5       NaN\n",
      "6      caba\n",
      "7      None\n",
      "8      bird\n",
      "9     horse\n",
      "10      dog\n",
      "dtype: object\n",
      "\n",
      "Length of the string values of the said Series:\n",
      "0     1.0\n",
      "1     1.0\n",
      "2     1.0\n",
      "3     4.0\n",
      "4     4.0\n",
      "5     NaN\n",
      "6     4.0\n",
      "7     NaN\n",
      "8     4.0\n",
      "9     5.0\n",
      "10    3.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "s = pd.Series(['X', 'Y', 'Z', 'Aaba', 'Baca', np.nan, 'CABA', None, 'bird', 'horse', 'dog'])\n",
    "print(\"Original series:\")\n",
    "print(s)\n",
    "print(\"\\nConvert all string values of the said Series to upper case:\")\n",
    "print(s.str.upper())\n",
    "print(\"\\nConvert all string values of the said Series to lower case:\")\n",
    "print(s.str.lower())\n",
    "print(\"\\nLength of the string values of the said Series:\")\n",
    "print(s.str.len())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to remove whitespaces, left sided whitespaces and right sided whitespaces of the string values of a given pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original series:\n",
      "Index([' Green', 'Black ', ' Red ', 'White', ' Pink '], dtype='object')\n",
      "\n",
      "Remove whitespace\n",
      "Index(['Green', 'Black', 'Red', 'White', 'Pink'], dtype='object')\n",
      "\n",
      "Remove left sided whitespace\n",
      "Index(['Green', 'Black ', 'Red ', 'White', 'Pink '], dtype='object')\n",
      "\n",
      "Remove Right sided whitespace\n",
      "Index([' Green', 'Black', ' Red', 'White', ' Pink'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "color1 = pd.Index([' Green', 'Black ', ' Red ', 'White', ' Pink '])\n",
    "print(\"Original series:\")\n",
    "print(color1)\n",
    "print(\"\\nRemove whitespace\")\n",
    "print(color1.str.strip())\n",
    "print(\"\\nRemove left sided whitespace\")\n",
    "print(color1.str.lstrip())\n",
    "print(\"\\nRemove Right sided whitespace\")\n",
    "print(color1.str.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to add leading zeros to the integer column in a pandas series and makes the length of the field to 8 digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe:\n",
      "   amount\n",
      "0      10\n",
      "1     250\n",
      "2    3000\n",
      "3   40000\n",
      "4  500000\n",
      "\n",
      "Add leading zeros:\n",
      "     amount\n",
      "0  00000010\n",
      "1  00000250\n",
      "2  00003000\n",
      "3  00040000\n",
      "4  00500000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nums = {'amount': [10, 250, 3000, 40000, 500000]}\n",
    "print(\"Original dataframe:\")\n",
    "df = pd.DataFrame(nums)\n",
    "print(df)\n",
    "print(\"\\nAdd leading zeros:\")\n",
    "df['amount'] = df['amount'].apply(lambda x: '{0:0>8}'.format(x))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to count of occurrence of a specified substring in a DataFrame column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  name_code date_of_birth    age\n",
      "0      c001     12/05/2002  18.5\n",
      "1      c002     16/02/1999  21.2\n",
      "2      c022     25/09/1998  22.5\n",
      "3     c2002     12/02/2022  22.0\n",
      "4     c2222     15/09/1997  23.0\n",
      "\n",
      "Count occurrence of 2 in date_of_birth column:\n",
      "  name_code date_of_birth    age  count\n",
      "0      c001     12/05/2002  18.5      0\n",
      "1      c002     16/02/1999  21.2      1\n",
      "2      c022     25/09/1998  22.5      2\n",
      "3     c2002     12/02/2022  22.0      2\n",
      "4     c2222     15/09/1997  23.0      4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'name_code': ['c001','c002','c022', 'c2002', 'c2222'],\n",
    "    'date_of_birth ': ['12/05/2002','16/02/1999','25/09/1998','12/02/2022','15/09/1997'],\n",
    "    'age': [18.5, 21.2, 22.5, 22, 23]\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nCount occurrence of 2 in date_of_birth column:\")\n",
    "df['count'] = list(map(lambda x: x.count(\"2\"), df['name_code']))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to find the index of a given substring of a DataFrame column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  name_code date_of_birth    age\n",
      "0      c001     12/05/2002  18.5\n",
      "1      c002     16/02/1999  21.2\n",
      "2      c022     25/09/1998  22.5\n",
      "3     c2002     12/02/2022  22.0\n",
      "4     c2222     15/09/1997  23.0\n",
      "\n",
      "Count occurrence of 22 in date_of_birth column:\n",
      "  name_code date_of_birth    age  Index\n",
      "0      c001     12/05/2002  18.5     -1\n",
      "1      c002     16/02/1999  21.2     -1\n",
      "2      c022     25/09/1998  22.5      2\n",
      "3     c2002     12/02/2022  22.0     -1\n",
      "4     c2222     15/09/1997  23.0      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'name_code': ['c001','c002','c022', 'c2002', 'c2222'],\n",
    "    'date_of_birth ': ['12/05/2002','16/02/1999','25/09/1998','12/02/2022','15/09/1997'],\n",
    "    'age': [18.5, 21.2, 22.5, 22, 23]\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nCount occurrence of 22 in date_of_birth column:\")\n",
    "df['Index'] = list(map(lambda x: x.find('22'), df['name_code']))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to find the index of a substring of DataFrame with beginning and end position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  name_code date_of_birth    age\n",
      "0     c0001     12/05/2002  18.5\n",
      "1     1000c     16/02/1999  21.2\n",
      "2     b00c2     25/09/1998  22.5\n",
      "3     b2c02     12/02/2022  22.0\n",
      "4     c2222     15/09/1997  23.0\n",
      "\n",
      "Index of a substring in a specified column of a dataframe:\n",
      "  name_code date_of_birth    age  Index\n",
      "0     c0001     12/05/2002  18.5      0\n",
      "1     1000c     16/02/1999  21.2      4\n",
      "2     b00c2     25/09/1998  22.5      3\n",
      "3     b2c02     12/02/2022  22.0      2\n",
      "4     c2222     15/09/1997  23.0      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'name_code': ['c0001','1000c','b00c2', 'b2c02', 'c2222'],\n",
    "    'date_of_birth ': ['12/05/2002','16/02/1999','25/09/1998','12/02/2022','15/09/1997'],\n",
    "    'age': [18.5, 21.2, 22.5, 22, 23]\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nIndex of a substring in a specified column of a dataframe:\")\n",
    "df['Index'] = list(map(lambda x: x.find('c', 0, 5), df['name_code']))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to check whether only numeric values present in a given column of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   company_code date_of_sale   sale_amount\n",
      "0       Company    12/05/2002      12348.5\n",
      "1  Company a001    16/02/1999     233331.2\n",
      "2          2055    25/09/1998         22.5\n",
      "3          abcd    12/02/2022    2566552.0\n",
      "4        123345    15/09/1997         23.0\n",
      "\n",
      "Numeric values present in company_code column:\n",
      "   company_code date_of_sale   sale_amount  company_code_is_digit\n",
      "0       Company    12/05/2002      12348.5                  False\n",
      "1  Company a001    16/02/1999     233331.2                  False\n",
      "2          2055    25/09/1998         22.5                   True\n",
      "3          abcd    12/02/2022    2566552.0                  False\n",
      "4        123345    15/09/1997         23.0                   True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'company_code': ['Company','Company a001', '2055', 'abcd', '123345'],\n",
    "    'date_of_sale ': ['12/05/2002','16/02/1999','25/09/1998','12/02/2022','15/09/1997'],\n",
    "    'sale_amount': [12348.5, 233331.2, 22.5, 2566552.0, 23.0]})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nNumeric values present in company_code column:\")\n",
    "df['company_code_is_digit'] = list(map(lambda x: x.isdigit(), df['company_code']))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to replace more than one value with other values in a given DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  company_code date_of_sale  sale_amount\n",
      "0            A   12/05/2002      12348.5\n",
      "1            B   16/02/1999     233331.2\n",
      "2            C   25/09/1998         22.5\n",
      "3            D   12/02/2022    2566552.0\n",
      "4            A   15/09/1997         23.0\n",
      "\n",
      "Replace A with c:\n",
      "  company_code date_of_sale  sale_amount\n",
      "0            X   12/05/2002      12348.5\n",
      "1            B   16/02/1999     233331.2\n",
      "2            C   25/09/1998         22.5\n",
      "3            Y   12/02/2022    2566552.0\n",
      "4            X   15/09/1997         23.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'company_code': ['A','B', 'C', 'D', 'A'],\n",
    "    'date_of_sale': ['12/05/2002','16/02/1999','25/09/1998','12/02/2022','15/09/1997'],\n",
    "    'sale_amount': [12348.5, 233331.2, 22.5, 2566552.0, 23.0]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nReplace A with c:\")\n",
    "df = df.replace([\"A\", \"D\"], [\"X\", \"Y\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to split a string of a column of a given DataFrame into multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "                 name date_of_birth    age\n",
      "0     Alberto  Franco     17/05/2002  18.5\n",
      "1    Gino Ann Mcneill     16/02/1999  21.2\n",
      "2        Ryan  Parkes     25/09/1998  22.5\n",
      "3  Eesha Artur Hinton     11/05/2002  22.0\n",
      "4       Syed  Wharton     15/09/1997  23.0\n",
      "\n",
      "New DataFrame:\n",
      "                 name date_of_birth    age    first middle     last\n",
      "0     Alberto  Franco     17/05/2002  18.5  Alberto          Franco\n",
      "1    Gino Ann Mcneill     16/02/1999  21.2     Gino    Ann  Mcneill\n",
      "2        Ryan  Parkes     25/09/1998  22.5     Ryan          Parkes\n",
      "3  Eesha Artur Hinton     11/05/2002  22.0    Eesha  Artur   Hinton\n",
      "4       Syed  Wharton     15/09/1997  23.0     Syed         Wharton\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alberto  Franco','Gino Ann Mcneill','Ryan  Parkes', 'Eesha Artur Hinton', 'Syed  Wharton'],\n",
    "    'date_of_birth ': ['17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [18.5, 21.2, 22.5, 22, 23]\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "df[[\"first\", \"middle\", \"last\"]] = df[\"name\"].str.split(\" \", expand = True)\n",
    "print(\"\\nNew DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to extract email from a specified column of string type of a given DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "                    name_email\n",
      "0  Alberto Franco af@gmail.com\n",
      "1    Gino Mcneill gm@yahoo.com\n",
      "2        Ryan Parkes rp@abc.io\n",
      "3                 Eesha Hinton\n",
      "4   Gino Mcneill gm@github.com\n",
      "\\Extracting email from dataframe columns:\n",
      "                    name_email          email\n",
      "0  Alberto Franco af@gmail.com   af@gmail.com\n",
      "1    Gino Mcneill gm@yahoo.com   gm@yahoo.com\n",
      "2        Ryan Parkes rp@abc.io      rp@abc.io\n",
      "3                 Eesha Hinton               \n",
      "4   Gino Mcneill gm@github.com  gm@github.com\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re as re\n",
    "pd.set_option('display.max_columns', 10)\n",
    "df = pd.DataFrame({\n",
    "    'name_email': ['Alberto Franco af@gmail.com','Gino Mcneill gm@yahoo.com','Ryan Parkes rp@abc.io', 'Eesha Hinton', 'Gino Mcneill gm@github.com']\n",
    "    })\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "def find_email(text):\n",
    "    email = re.findall(r'[\\w\\.-]+@[\\w\\.-]+',str(text))\n",
    "    return \",\".join(email)\n",
    "df['email']=df['name_email'].apply(lambda x: find_email(x))\n",
    "print(\"\\Extracting email from dataframe columns:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to extract hash attached word from twitter text from the specified column of a given DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "                                  tweets\n",
      "0                    #Obama says goodbye\n",
      "1                     Retweets for #cash\n",
      "2  A political endorsement in #Indonesia\n",
      "3                 1 dog = many #retweets\n",
      "4                     Just a simple #egg\n",
      "\\Extracting#@word from dataframe columns:\n",
      "                                  tweets  hash_word\n",
      "0                    #Obama says goodbye      Obama\n",
      "1                     Retweets for #cash       cash\n",
      "2  A political endorsement in #Indonesia  Indonesia\n",
      "3                 1 dog = many #retweets   retweets\n",
      "4                     Just a simple #egg        egg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re as re\n",
    "pd.set_option('display.max_columns', 10)\n",
    "df = pd.DataFrame({\n",
    "    'tweets': ['#Obama says goodbye','Retweets for #cash','A political endorsement in #Indonesia', '1 dog = many #retweets', 'Just a simple #egg']\n",
    "    })\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "def find_hash(text):\n",
    "    hword=re.findall(r'(?<=#)\\w+',text)\n",
    "    return \" \".join(hword)\n",
    "df['hash_word']=df['tweets'].apply(lambda x: find_hash(x))\n",
    "print(\"\\Extracting#@word from dataframe columns:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to extract only phone number from the specified column of a given DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  company_code               company_phone_no\n",
      "0        c0001  Company1-Phone no. 4695168357\n",
      "1        c0002  Company2-Phone no. 8088729013\n",
      "2        c0003  Company3-Phone no. 6204658086\n",
      "3        c0003  Company4-Phone no. 5159530096\n",
      "4        c0004  Company5-Phone no. 9037952371\n",
      "\\Extracting numbers from dataframe columns:\n",
      "  company_code               company_phone_no      number\n",
      "0        c0001  Company1-Phone no. 4695168357  4695168357\n",
      "1        c0002  Company2-Phone no. 8088729013  8088729013\n",
      "2        c0003  Company3-Phone no. 6204658086  6204658086\n",
      "3        c0003  Company4-Phone no. 5159530096  5159530096\n",
      "4        c0004  Company5-Phone no. 9037952371  9037952371\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re as re\n",
    "pd.set_option('display.max_columns', 10)\n",
    "df = pd.DataFrame({\n",
    "    'company_code': ['c0001','c0002','c0003', 'c0003', 'c0004'],\n",
    "    'company_phone_no': ['Company1-Phone no. 4695168357','Company2-Phone no. 8088729013','Company3-Phone no. 6204658086', 'Company4-Phone no. 5159530096', 'Company5-Phone no. 9037952371']\n",
    "    })\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "def find_phone_number(text):\n",
    "    ph_no = re.findall(r\"\\b\\d{10}\\b\",text)\n",
    "    return \"\".join(ph_no)\n",
    "df['number']=df['company_phone_no'].apply(lambda x: find_phone_number(x))\n",
    "print(\"\\Extracting numbers from dataframe columns:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to extract year between 1800 to 2200 from the specified column of a given DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  company_code       year\n",
      "0        c0001  year 1800\n",
      "1        c0002  year 1700\n",
      "2        c0003  year 2300\n",
      "3        c0003  year 1900\n",
      "4        c0004  year 2200\n",
      "\\Extracting year between 1800 to 2200:\n",
      "  company_code       year year_range\n",
      "0        c0001  year 1800     [1800]\n",
      "1        c0002  year 1700         []\n",
      "2        c0003  year 2300         []\n",
      "3        c0003  year 1900     [1900]\n",
      "4        c0004  year 2200     [2200]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re as re\n",
    "pd.set_option('display.max_columns', 10)\n",
    "df = pd.DataFrame({\n",
    "    'company_code': ['c0001','c0002','c0003', 'c0003', 'c0004'],\n",
    "    'year': ['year 1800','year 1700','year 2300', 'year 1900', 'year 2200']\n",
    "    })\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "def find_year(text):\n",
    "    #line=re.findall(r\"\\b(18[0][0]|2[0-2][00])\\b\",text)\n",
    "    result = re.findall(r\"\\b(18[0-9]{2}|19[0-8][0-9]|199[0-9]|2[01][0-9]{2}|2200)\\b\",text)\n",
    "    return result\n",
    "df['year_range']=df['year'].apply(lambda x: find_year(x))\n",
    "print(\"\\Extracting year between 1800 to 2200:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to extract only non alphanumeric characters from the specified column of a given DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  company_code       year\n",
      "0       c0001#  year 1800\n",
      "1      c00@0^2  year 1700\n",
      "2       $c0003  year 2300\n",
      "3        c0003  year 1900\n",
      "4       &c0004  year 2200\n",
      "\\Extracting only non alphanumeric characters from company_code:\n",
      "  company_code       year nonalpha\n",
      "0       c0001#  year 1800      [#]\n",
      "1      c00@0^2  year 1700   [@, ^]\n",
      "2       $c0003  year 2300      [$]\n",
      "3        c0003  year 1900       []\n",
      "4       &c0004  year 2200      [&]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re as re\n",
    "pd.set_option('display.max_columns', 10)\n",
    "df = pd.DataFrame({\n",
    "    'company_code': ['c0001#','c00@0^2','$c0003', 'c0003', '&c0004'],\n",
    "    'year': ['year 1800','year 1700','year 2300', 'year 1900', 'year 2200']\n",
    "    })\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "def find_nonalpha(text):\n",
    "    result = re.findall(\"[^A-Za-z0-9 ]\",text)\n",
    "    return result\n",
    "df['nonalpha']=df['company_code'].apply(lambda x: find_nonalpha(x))\n",
    "print(\"\\Extracting only non alphanumeric characters from company_code:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to extract only punctuations from the specified column of a given DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  company_code       year\n",
      "0       c0001.  year 1800\n",
      "1       c000,2  year 1700\n",
      "2        c0003  year 2300\n",
      "3       c0003#  year 1900\n",
      "4       c0004,  year 2200\n",
      "\n",
      "Extracting punctuation:\n",
      "  company_code       year nonalpha\n",
      "0       c0001.  year 1800      [.]\n",
      "1       c000,2  year 1700      [,]\n",
      "2        c0003  year 2300       []\n",
      "3       c0003#  year 1900      [#]\n",
      "4       c0004,  year 2200      [,]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re as re\n",
    "pd.set_option('display.max_columns', 10)\n",
    "df = pd.DataFrame({\n",
    "    'company_code': ['c0001.','c000,2','c0003', 'c0003#', 'c0004,'],\n",
    "    'year': ['year 1800','year 1700','year 2300', 'year 1900', 'year 2200']\n",
    "    })\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "def find_punctuations(text):\n",
    "    result = re.findall(r'[!\"\\$%&\\'()*+,\\-.\\/:;=#@?\\[\\\\\\]^_`{|}~]*', text)\n",
    "    string=\"\".join(result)\n",
    "    return list(string)\n",
    "df['nonalpha']=df['company_code'].apply(lambda x: find_punctuations(x))\n",
    "print(\"\\nExtracting punctuation:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Write a Pandas program to remove repetitive characters from the specified column of a given DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  text_code                    text_lang\n",
      "0    t0001.      She livedd a long life.\n",
      "1     t0002     How oold is your father?\n",
      "2     t0003        What is tthe problem?\n",
      "3     t0004  TThhis desk is used by Tom.\n",
      "\n",
      "Remove repetitive characters:\n",
      "  text_code                    text_lang                normal_text\n",
      "0    t0001.      She livedd a long life.     She lived a long life.\n",
      "1     t0002     How oold is your father?    How old is your father?\n",
      "2     t0003        What is tthe problem?       What is the problem?\n",
      "3     t0004  TThhis desk is used by Tom.  This desk is used by Tom.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re as re\n",
    "pd.set_option('display.max_columns', 10)\n",
    "df = pd.DataFrame({\n",
    "    'text_code': ['t0001.','t0002','t0003', 't0004'],\n",
    "    'text_lang': ['She livedd a long life.', 'How oold is your father?', 'What is tthe problem?','TThhis desk is used by Tom.']\n",
    "    })\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "def rep_char(str1):\n",
    "    tchr = str1.group(0)\n",
    "    if len(tchr) > 1:\n",
    "        return tchr[0:1] # can change the value here on repetition\n",
    "def unique_char(rep, sent_text):\n",
    "    convert = re.sub(r'(\\w)\\1+', rep, sent_text) \n",
    "    return convert\n",
    "df['normal_text']=df['text_lang'].apply(lambda x : unique_char(rep_char,x))\n",
    "print(\"\\nRemove repetitive characters:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to extract numbers less than 100 from the specified column of a given DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  company_code                   address\n",
      "0        c0001          72 Surrey Ave.11\n",
      "1        c0002         92 N. Bishop Ave.\n",
      "2        c0003      9910 Golden Star St.\n",
      "3        c0003            102 Dunbar St.\n",
      "4        c0004  17 West Livingston Court\n",
      "\n",
      "Number less than 100:\n",
      "  company_code                   address num_less\n",
      "0        c0001          72 Surrey Ave.11    72 11\n",
      "1        c0002         92 N. Bishop Ave.       92\n",
      "2        c0003      9910 Golden Star St.         \n",
      "3        c0003            102 Dunbar St.         \n",
      "4        c0004  17 West Livingston Court       17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re as re\n",
    "pd.set_option('display.max_columns', 10)\n",
    "df = pd.DataFrame({\n",
    "    'company_code': ['c0001','c0002','c0003', 'c0003', 'c0004'],\n",
    "    'address': ['72 Surrey Ave.11','92 N. Bishop Ave.','9910 Golden Star St.', '102 Dunbar St.', '17 West Livingston Court']\n",
    "    })\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "def test_num_less(n):\n",
    "    nums = []\n",
    "    for i in n.split():\n",
    "        result = re.findall(r'\\b(0*(?:[1-9][0-9]?|100))\\b',i)\n",
    "        nums.append(result)\n",
    "        all_num=[\",\".join(x) for x in nums if x != []]\n",
    "    return \" \".join(all_num)\n",
    "\n",
    "df['num_less'] = df['address'].apply(lambda x : test_num_less(x))\n",
    "print(\"\\nNumber less than 100:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Write a Pandas program to extract date (format: mm-dd-yyyy) from a given column of a given DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  company_code date_of_sale  sale_amount\n",
      "0         Abcd   12/05/2002      12348.5\n",
      "1         EFGF   16/02/1999     233331.2\n",
      "2      zefsalf   05/09/1998         22.5\n",
      "3      sdfslew   12/02/2022    2566552.0\n",
      "4      zekfsdf   15/09/1997         23.0\n",
      "\n",
      "Valid dates (format: mm-dd-yyyy):\n",
      "  company_code date_of_sale  sale_amount       valid_dates\n",
      "0         Abcd   12/05/2002      12348.5  [(12, 05, 2002)]\n",
      "1         EFGF   16/02/1999     233331.2                []\n",
      "2      zefsalf   05/09/1998         22.5  [(05, 09, 1998)]\n",
      "3      sdfslew   12/02/2022    2566552.0  [(12, 02, 2022)]\n",
      "4      zekfsdf   15/09/1997         23.0                []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re as re\n",
    "df = pd.DataFrame({\n",
    "    'company_code': ['Abcd','EFGF', 'zefsalf', 'sdfslew', 'zekfsdf'],\n",
    "    'date_of_sale': ['12/05/2002','16/02/1999','05/09/1998','12/02/2022','15/09/1997'],\n",
    "    'sale_amount': [12348.5, 233331.2, 22.5, 2566552.0, 23.0]\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "def find_valid_dates(dt):\n",
    "    #format: mm-dd-yyyy\n",
    "    result = re.findall(r'\\b(1[0-2]|0[1-9])/(3[01]|[12][0-9]|0[1-9])/([0-9]{4})\\b',dt)\n",
    "    return result\n",
    "df['valid_dates']=df['date_of_sale'].apply(lambda dt : find_valid_dates(dt))\n",
    "print(\"\\nValid dates (format: mm-dd-yyyy):\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a Pandas program to create\n",
    "a) Datetime object for Jan 15 2012.\n",
    "b) Specific date and time of 9:20 pm.\n",
    "c) Local date and time.\n",
    "d) A date without time.\n",
    "e) Current date.\n",
    "f) Time from a datetime.\n",
    "g) Current local time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime object for Jan 11 2012:\n",
      "2012-01-11 00:00:00\n",
      "2023-11-12 21:27:33.595048\n",
      "2023-11-12\n",
      "21:27:33.595048\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(\"Datetime object for Jan 11 2012:\")\n",
    "print(datetime(2012,1,11))\n",
    "print(datetime.now())\n",
    "print(datetime.now().date())\n",
    "print(datetime.now().time())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Write a Pandas program to create a date from a given year, month, day and another date from a given string formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-12 00:00:00\n"
     ]
    }
   ],
   "source": [
    "d=datetime(year=2023,month=11,day=12)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to print the day after and before a specified date. Also print the days between two given dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-13\n",
      "Yesterday: 2023-11-11\n",
      "\n",
      "Difference between two dates:  14 days, 0:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "today=datetime.now().date()\n",
    "\n",
    "tmrw=today+pd.Timedelta(days=1)\n",
    "print(tmrw)\n",
    "\n",
    "yesterday = today - pd.Timedelta(days=1)\n",
    "print(\"Yesterday:\", yesterday)\n",
    "\n",
    "date1 = datetime(2016, 8, 2)\n",
    "date2 = datetime(2016, 7, 19)\n",
    "print(\"\\nDifference between two dates: \",(date1 - date2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to create a time-series from a given list of dates as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014-08-01    0.304222\n",
      "2014-08-02    0.226928\n",
      "2014-08-03    0.280396\n",
      "2014-08-04    0.737930\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime, date \n",
    "dates = ['2014-08-01','2014-08-02','2014-08-03','2014-08-04']\n",
    "time_series = pd.Series(np.random.randn(4), dates)\n",
    "print(time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to calculate all Thursdays between two given days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Thursdays between 2020-01-01 and 2020-12-31:\n",
      "\n",
      "['2020-01-02T00:00:00.000000000' '2020-01-09T00:00:00.000000000'\n",
      " '2020-01-16T00:00:00.000000000' '2020-01-23T00:00:00.000000000'\n",
      " '2020-01-30T00:00:00.000000000' '2020-02-06T00:00:00.000000000'\n",
      " '2020-02-13T00:00:00.000000000' '2020-02-20T00:00:00.000000000'\n",
      " '2020-02-27T00:00:00.000000000' '2020-03-05T00:00:00.000000000'\n",
      " '2020-03-12T00:00:00.000000000' '2020-03-19T00:00:00.000000000'\n",
      " '2020-03-26T00:00:00.000000000' '2020-04-02T00:00:00.000000000'\n",
      " '2020-04-09T00:00:00.000000000' '2020-04-16T00:00:00.000000000'\n",
      " '2020-04-23T00:00:00.000000000' '2020-04-30T00:00:00.000000000'\n",
      " '2020-05-07T00:00:00.000000000' '2020-05-14T00:00:00.000000000'\n",
      " '2020-05-21T00:00:00.000000000' '2020-05-28T00:00:00.000000000'\n",
      " '2020-06-04T00:00:00.000000000' '2020-06-11T00:00:00.000000000'\n",
      " '2020-06-18T00:00:00.000000000' '2020-06-25T00:00:00.000000000'\n",
      " '2020-07-02T00:00:00.000000000' '2020-07-09T00:00:00.000000000'\n",
      " '2020-07-16T00:00:00.000000000' '2020-07-23T00:00:00.000000000'\n",
      " '2020-07-30T00:00:00.000000000' '2020-08-06T00:00:00.000000000'\n",
      " '2020-08-13T00:00:00.000000000' '2020-08-20T00:00:00.000000000'\n",
      " '2020-08-27T00:00:00.000000000' '2020-09-03T00:00:00.000000000'\n",
      " '2020-09-10T00:00:00.000000000' '2020-09-17T00:00:00.000000000'\n",
      " '2020-09-24T00:00:00.000000000' '2020-10-01T00:00:00.000000000'\n",
      " '2020-10-08T00:00:00.000000000' '2020-10-15T00:00:00.000000000'\n",
      " '2020-10-22T00:00:00.000000000' '2020-10-29T00:00:00.000000000'\n",
      " '2020-11-05T00:00:00.000000000' '2020-11-12T00:00:00.000000000'\n",
      " '2020-11-19T00:00:00.000000000' '2020-11-26T00:00:00.000000000'\n",
      " '2020-12-03T00:00:00.000000000' '2020-12-10T00:00:00.000000000'\n",
      " '2020-12-17T00:00:00.000000000' '2020-12-24T00:00:00.000000000'\n",
      " '2020-12-31T00:00:00.000000000']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "thursdays  = pd.date_range('2020-01-01', \n",
    "                           '2020-12-31', freq=\"W-THU\")\n",
    "print(\"All Thursdays between 2020-01-01 and 2020-12-31:\\n\")\n",
    "print(thursdays.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "World alcohol consumption dataset\n",
    "This is a global beverage consumption record dataset. The first column means the year of the record, the second column refers to the place where the beverage was produced, and the third column refers to the place where the beverage was consumed. The fourth columns refer to the types of beverages, and the fifth column refers to the average consumption of beverages per person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Pandas program to display the dimensions or shape of the World alcohol consumption dataset. Also extract the column names from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n",
      "Index(['Year', 'WHO region', 'Country', 'Beverage Types', 'Display Value'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('d://MLDataSet//world_alcohol.csv')\n",
    "df.head()\n",
    "print(df.shape)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select first 2 rows, 2 columns and specific two columns from World alcohol consumption dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>WHO region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Beverage Types</th>\n",
       "      <th>Display Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986</td>\n",
       "      <td>Western Pacific</td>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>Wine</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year       WHO region   Country Beverage Types  Display Value\n",
       "0  1986  Western Pacific  Viet Nam           Wine            0.0\n",
       "1  1986         Americas   Uruguay          Other            0.5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>WHO region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986</td>\n",
       "      <td>Western Pacific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986</td>\n",
       "      <td>Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986</td>\n",
       "      <td>Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1984</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1985</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1984</td>\n",
       "      <td>South-East Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1984</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1985</td>\n",
       "      <td>South-East Asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year       WHO region\n",
       "0   1986  Western Pacific\n",
       "1   1986         Americas\n",
       "2   1985           Africa\n",
       "3   1986         Americas\n",
       "4   1987         Americas\n",
       "..   ...              ...\n",
       "95  1984           Africa\n",
       "96  1985           Europe\n",
       "97  1984  South-East Asia\n",
       "98  1984           Africa\n",
       "99  1985  South-East Asia\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select random number of rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>WHO region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Beverage Types</th>\n",
       "      <th>Display Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1985</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>Spirits</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1987</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Trinidad and Tobago</td>\n",
       "      <td>Spirits</td>\n",
       "      <td>2.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1989</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Seychelles</td>\n",
       "      <td>Beer</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1987</td>\n",
       "      <td>Eastern Mediterranean</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>Wine</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1987</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Botswana</td>\n",
       "      <td>Wine</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year             WHO region              Country Beverage Types  \\\n",
       "94  1985                 Europe              Ukraine        Spirits   \n",
       "46  1987               Americas  Trinidad and Tobago        Spirits   \n",
       "17  1989                 Africa           Seychelles           Beer   \n",
       "66  1987  Eastern Mediterranean                 Iraq           Wine   \n",
       "10  1987                 Africa             Botswana           Wine   \n",
       "\n",
       "    Display Value  \n",
       "94           3.06  \n",
       "46           2.26  \n",
       "17           2.23  \n",
       "66           0.01  \n",
       "10           0.20  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nSelect random number of rows:\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  WHO region  Country  Beverage Types  Display Value\n",
      "0   False       False    False           False          False\n",
      "1   False       False    False           False          False\n",
      "2   False       False    False           False          False\n",
      "3   False       False    False           False          False\n",
      "4   False       False    False           False          False\n",
      "..    ...         ...      ...             ...            ...\n",
      "95  False       False    False           False          False\n",
      "96  False       False    False           False          False\n",
      "97  False       False    False           False          False\n",
      "98  False       False    False           False          False\n",
      "99  False       False    False           False          False\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>WHO region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Beverage Types</th>\n",
       "      <th>Display Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986</td>\n",
       "      <td>Western Pacific</td>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>Wine</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Cte d'Ivoire</td>\n",
       "      <td>Wine</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1986</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>Beer</td>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1987</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Saint Kitts and Nevis</td>\n",
       "      <td>Beer</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1984</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Niger</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1985</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>Wine</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1984</td>\n",
       "      <td>South-East Asia</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>Wine</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1984</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Equatorial Guinea</td>\n",
       "      <td>Wine</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1985</td>\n",
       "      <td>South-East Asia</td>\n",
       "      <td>Democratic People's Republic of Korea</td>\n",
       "      <td>Wine</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year       WHO region                                Country  \\\n",
       "0   1986  Western Pacific                               Viet Nam   \n",
       "1   1986         Americas                                Uruguay   \n",
       "2   1985           Africa                           Cte d'Ivoire   \n",
       "3   1986         Americas                               Colombia   \n",
       "4   1987         Americas                  Saint Kitts and Nevis   \n",
       "..   ...              ...                                    ...   \n",
       "95  1984           Africa                                  Niger   \n",
       "96  1985           Europe                             Luxembourg   \n",
       "97  1984  South-East Asia                              Indonesia   \n",
       "98  1984           Africa                      Equatorial Guinea   \n",
       "99  1985  South-East Asia  Democratic People's Republic of Korea   \n",
       "\n",
       "   Beverage Types  Display Value  \n",
       "0            Wine           0.00  \n",
       "1           Other           0.50  \n",
       "2            Wine           1.62  \n",
       "3            Beer           4.27  \n",
       "4            Beer           1.98  \n",
       "..            ...            ...  \n",
       "95          Other           0.00  \n",
       "96           Wine           7.38  \n",
       "97           Wine           0.00  \n",
       "98           Wine           0.00  \n",
       "99           Wine           0.00  \n",
       "\n",
       "[95 rows x 5 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find and drop the missing values from World alcohol consumption dataset.\n",
    "print(df.isnull())\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>WHO region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Beverage Types</th>\n",
       "      <th>Display Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1986</td>\n",
       "      <td>Western Pacific</td>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>Wine</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1986</td>\n",
       "      <td>Americas</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Cte d'Ivoire</td>\n",
       "      <td>Wine</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1984</td>\n",
       "      <td>Eastern Mediterranean</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1984</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Norway</td>\n",
       "      <td>Spirits</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1986</td>\n",
       "      <td>South-East Asia</td>\n",
       "      <td>Myanmar</td>\n",
       "      <td>Wine</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year             WHO region       Country Beverage Types  Display Value\n",
       "0   1986        Western Pacific      Viet Nam           Wine           0.00\n",
       "1   1986               Americas       Uruguay          Other           0.50\n",
       "2   1985                 Africa  Cte d'Ivoire           Wine           1.62\n",
       "13  1984  Eastern Mediterranean   Afghanistan          Other           0.00\n",
       "18  1984                 Europe        Norway        Spirits           1.62\n",
       "20  1986        South-East Asia       Myanmar           Wine           0.00"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove the duplicates from 'WHO region' column of World alcohol consumption dataset.\n",
    "\n",
    "df.drop_duplicates('WHO region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The world alcohol consumption details in the year 1985:\n",
      "    Year       WHO region                                            Country  \\\n",
      "2   1985           Africa                                       Cte d'Ivoire   \n",
      "7   1985           Africa                                             Angola   \n",
      "12  1985  Western Pacific                   Lao People's Democratic Republic   \n",
      "14  1985  Western Pacific                                           Viet Nam   \n",
      "24  1985           Africa                                            Comoros   \n",
      "26  1985           Europe  United Kingdom of Great Britain and Northern I...   \n",
      "33  1985           Africa                                         Mauritania   \n",
      "35  1985         Americas                              Saint Kitts and Nevis   \n",
      "44  1985           Europe                                          Lithuania   \n",
      "50  1985           Europe                                        Switzerland   \n",
      "\n",
      "   Beverage Types  Display Value  \n",
      "2            Wine           1.62  \n",
      "7         Spirits           0.39  \n",
      "12           Beer           0.00  \n",
      "14        Spirits           0.05  \n",
      "24          Other            NaN  \n",
      "26           Wine           1.36  \n",
      "33          Other           0.00  \n",
      "35        Spirits           2.24  \n",
      "44          Other            NaN  \n",
      "50          Other           0.30  \n",
      "\n",
      "The world alcohol consumption details in the year 1989:\n",
      "    Year             WHO region                           Country  \\\n",
      "11  1989               Americas                         Guatemala   \n",
      "17  1989                 Africa                        Seychelles   \n",
      "21  1989               Americas                        Costa Rica   \n",
      "32  1989                 Africa                         Mauritius   \n",
      "45  1989                 Africa                          Zimbabwe   \n",
      "55  1989               Americas                          Suriname   \n",
      "57  1989                 Europe                           Croatia   \n",
      "59  1989  Eastern Mediterranean              Syrian Arab Republic   \n",
      "64  1989               Americas  Bolivia (Plurinational State of)   \n",
      "65  1989  Eastern Mediterranean                           Somalia   \n",
      "\n",
      "   Beverage Types  Display Value  \n",
      "11           Beer           0.62  \n",
      "17           Beer           2.23  \n",
      "21        Spirits           4.51  \n",
      "32           Beer           1.60  \n",
      "45           Beer           0.19  \n",
      "55           Wine           0.04  \n",
      "57           Wine           5.10  \n",
      "59          Other           0.00  \n",
      "64           Beer           1.26  \n",
      "65           Beer           0.00  \n",
      "\n",
      "The world alcohol consumption details where year is 1987 or 1989:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'float' and 'bool'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:301\u001b[0m, in \u001b[0;36mna_logical_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;66;03m# For exposition, write:\u001b[39;00m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m#  yarr = isinstance(y, np.ndarray)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# Then Cases where this goes through without raising include:\u001b[39;00m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;66;03m#  (xint or xbool) and (yint or bool)\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'float' and 'bool'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [83]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1989\u001b[39m]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThe world alcohol consumption details where year is 1987 or 1989:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m1985\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m1989\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     68\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:78\u001b[0m, in \u001b[0;36mOpsMixin.__or__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__or__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__or__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logical_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mor_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6946\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6942\u001b[0m other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n\u001b[0;32m   6944\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_FRAME(\u001b[38;5;28mself\u001b[39m, other, axis, flex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 6946\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_frame_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6985\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[1;34m(self, right, func, axis)\u001b[0m\n\u001b[0;32m   6979\u001b[0m     \u001b[38;5;66;03m# TODO: The previous assertion `assert right._indexed_same(self)`\u001b[39;00m\n\u001b[0;32m   6980\u001b[0m     \u001b[38;5;66;03m#  fails in cases with empty columns reached via\u001b[39;00m\n\u001b[0;32m   6981\u001b[0m     \u001b[38;5;66;03m#  _frame_arith_method_with_reindex\u001b[39;00m\n\u001b[0;32m   6982\u001b[0m \n\u001b[0;32m   6983\u001b[0m     \u001b[38;5;66;03m# TODO operate_blockwise expects a manager of the same type\u001b[39;00m\n\u001b[0;32m   6984\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 6985\u001b[0m         bm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperate_blockwise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6986\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# error: Argument 1 to \"operate_blockwise\" of \"ArrayManager\" has\u001b[39;49;00m\n\u001b[0;32m   6987\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;49;00m\n\u001b[0;32m   6988\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# \"ArrayManager\"\u001b[39;49;00m\n\u001b[0;32m   6989\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# error: Argument 1 to \"operate_blockwise\" of \"BlockManager\" has\u001b[39;49;00m\n\u001b[0;32m   6990\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;49;00m\n\u001b[0;32m   6991\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# \"BlockManager\"\u001b[39;49;00m\n\u001b[0;32m   6992\u001b[0m \u001b[43m            \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   6993\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6994\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6995\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(bm)\n\u001b[0;32m   6997\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, Series) \u001b[38;5;129;01mand\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   6998\u001b[0m     \u001b[38;5;66;03m# axis=1 means we want to operate row-by-row\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1409\u001b[0m, in \u001b[0;36mBlockManager.operate_blockwise\u001b[1;34m(self, other, array_op)\u001b[0m\n\u001b[0;32m   1405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moperate_blockwise\u001b[39m(\u001b[38;5;28mself\u001b[39m, other: BlockManager, array_op) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BlockManager:\n\u001b[0;32m   1406\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;124;03m    Apply array_op blockwise with another (aligned) BlockManager.\u001b[39;00m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperate_blockwise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray_op\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\ops.py:63\u001b[0m, in \u001b[0;36moperate_blockwise\u001b[1;34m(left, right, array_op)\u001b[0m\n\u001b[0;32m     61\u001b[0m res_blks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lvals, rvals, locs, left_ea, right_ea, rblk \u001b[38;5;129;01min\u001b[39;00m _iter_block_pairs(left, right):\n\u001b[1;32m---> 63\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43marray_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m left_ea \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m right_ea \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(res_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     65\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:391\u001b[0m, in \u001b[0;36mlogical_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# For int vs int `^`, `|`, `&` are bitwise operators and return\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m#   integer dtypes.  Otherwise these are boolean ops\u001b[39;00m\n\u001b[0;32m    389\u001b[0m filler \u001b[38;5;241m=\u001b[39m fill_int \u001b[38;5;28;01mif\u001b[39;00m is_self_int_dtype \u001b[38;5;129;01mand\u001b[39;00m is_other_int_dtype \u001b[38;5;28;01melse\u001b[39;00m fill_bool\n\u001b[1;32m--> 391\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mna_logical_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# error: Cannot call function of unknown type\u001b[39;00m\n\u001b[0;32m    393\u001b[0m res_values \u001b[38;5;241m=\u001b[39m filler(res_values)  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:308\u001b[0m, in \u001b[0;36mna_logical_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    306\u001b[0m     x \u001b[38;5;241m=\u001b[39m ensure_object(x)\n\u001b[0;32m    307\u001b[0m     y \u001b[38;5;241m=\u001b[39m ensure_object(y)\n\u001b[1;32m--> 308\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvec_binop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;66;03m# let null fall thru\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_scalar(y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\ops.pyx:252\u001b[0m, in \u001b[0;36mpandas._libs.ops.vec_binop\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\ops.pyx:245\u001b[0m, in \u001b[0;36mpandas._libs.ops.vec_binop\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'float' and 'bool'"
     ]
    }
   ],
   "source": [
    "# find out the alcohol consumption of a given year from the world alcohol consumption dataset.\n",
    "\n",
    "print(\"\\nThe world alcohol consumption details in the year 1985:\")\n",
    "print(df[df['Year']==1985].head(10))\n",
    "print(\"\\nThe world alcohol consumption details in the year 1989:\")\n",
    "print(df[df['Year']==1989].head(10))\n",
    "\n",
    "print(\"\\nThe world alcohol consumption details where year is 1987 or 1989:\")\n",
    "print((df[df['Year']==1985]) | (df[df['Year']==1989]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Year             WHO region                                Country  \\\n",
      "13  1984  Eastern Mediterranean                            Afghanistan   \n",
      "20  1986        South-East Asia                                Myanmar   \n",
      "25  1984  Eastern Mediterranean                                Tunisia   \n",
      "27  1984  Eastern Mediterranean                                Bahrain   \n",
      "36  1987  Eastern Mediterranean                                  Egypt   \n",
      "38  1987  Eastern Mediterranean                                  Qatar   \n",
      "52  1986  Eastern Mediterranean                           Saudi Arabia   \n",
      "53  1984  Eastern Mediterranean                                 Kuwait   \n",
      "58  1984  Eastern Mediterranean                                Somalia   \n",
      "59  1989  Eastern Mediterranean                   Syrian Arab Republic   \n",
      "60  1987  Eastern Mediterranean             Iran (Islamic Republic of)   \n",
      "63  1985  Eastern Mediterranean                                  Libya   \n",
      "65  1989  Eastern Mediterranean                                Somalia   \n",
      "66  1987  Eastern Mediterranean                                   Iraq   \n",
      "73  1986  Eastern Mediterranean                               Pakistan   \n",
      "75  1989  Eastern Mediterranean                            Afghanistan   \n",
      "84  1986        South-East Asia                              Sri Lanka   \n",
      "87  1989  Eastern Mediterranean                                   Iraq   \n",
      "88  1987  Eastern Mediterranean                                Lebanon   \n",
      "89  1986  Eastern Mediterranean                                Lebanon   \n",
      "97  1984        South-East Asia                              Indonesia   \n",
      "99  1985        South-East Asia  Democratic People's Republic of Korea   \n",
      "\n",
      "   Beverage Types  Display Value  \n",
      "13          Other           0.00  \n",
      "20           Wine           0.00  \n",
      "25          Other           0.00  \n",
      "27           Beer           2.22  \n",
      "36           Beer           0.07  \n",
      "38          Other           0.00  \n",
      "52           Wine           0.00  \n",
      "53           Beer           0.00  \n",
      "58        Spirits           0.00  \n",
      "59          Other           0.00  \n",
      "60          Other           0.00  \n",
      "63          Other           0.00  \n",
      "65           Beer           0.00  \n",
      "66           Wine           0.01  \n",
      "73          Other           0.01  \n",
      "75          Other           0.00  \n",
      "84          Other           0.00  \n",
      "87           Wine           0.01  \n",
      "88           Beer           0.42  \n",
      "89           Wine           0.70  \n",
      "97           Wine           0.00  \n",
      "99           Wine           0.00  \n"
     ]
    }
   ],
   "source": [
    "print(df[df[\"WHO region\"].str.contains(\"Ea\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select all rows which not appears in a given list:\n",
      "    Year       WHO region                                Country  \\\n",
      "0   1986  Western Pacific                               Viet Nam   \n",
      "1   1986         Americas                                Uruguay   \n",
      "3   1986         Americas                               Colombia   \n",
      "4   1987         Americas                  Saint Kitts and Nevis   \n",
      "5   1987         Americas                              Guatemala   \n",
      "8   1986         Americas                    Antigua and Barbuda   \n",
      "11  1989         Americas                              Guatemala   \n",
      "12  1985  Western Pacific       Lao People's Democratic Republic   \n",
      "14  1985  Western Pacific                               Viet Nam   \n",
      "16  1984         Americas                             Costa Rica   \n",
      "20  1986  South-East Asia                                Myanmar   \n",
      "21  1989         Americas                             Costa Rica   \n",
      "28  1987  Western Pacific                               Viet Nam   \n",
      "31  1986  Western Pacific       Micronesia (Federated States of)   \n",
      "35  1985         Americas                  Saint Kitts and Nevis   \n",
      "43  1984  Western Pacific                                  China   \n",
      "46  1987         Americas                    Trinidad and Tobago   \n",
      "47  1986         Americas                                 Mexico   \n",
      "48  1987         Americas                              Nicaragua   \n",
      "54  1984         Americas                            El Salvador   \n",
      "55  1989         Americas                               Suriname   \n",
      "56  1987  Western Pacific                               Viet Nam   \n",
      "61  1984  Western Pacific                       Papua New Guinea   \n",
      "62  1987         Americas                               Suriname   \n",
      "64  1989         Americas       Bolivia (Plurinational State of)   \n",
      "74  1986         Americas       Bolivia (Plurinational State of)   \n",
      "78  1989         Americas                                Jamaica   \n",
      "84  1986  South-East Asia                              Sri Lanka   \n",
      "86  1986         Americas                                Bahamas   \n",
      "97  1984  South-East Asia                              Indonesia   \n",
      "99  1985  South-East Asia  Democratic People's Republic of Korea   \n",
      "\n",
      "   Beverage Types  Display Value  \n",
      "0            Wine           0.00  \n",
      "1           Other           0.50  \n",
      "3            Beer           4.27  \n",
      "4            Beer           1.98  \n",
      "5           Other           0.00  \n",
      "8         Spirits           1.55  \n",
      "11           Beer           0.62  \n",
      "12           Beer           0.00  \n",
      "14        Spirits           0.05  \n",
      "16           Wine           0.06  \n",
      "20           Wine           0.00  \n",
      "21        Spirits           4.51  \n",
      "28           Beer           0.11  \n",
      "31           Wine           0.00  \n",
      "35        Spirits           2.24  \n",
      "43           Wine           0.03  \n",
      "46        Spirits           2.26  \n",
      "47          Other           0.04  \n",
      "48           Beer           0.70  \n",
      "54        Spirits           1.81  \n",
      "55           Wine           0.04  \n",
      "56           Wine           0.00  \n",
      "61        Spirits           0.08  \n",
      "62          Other           0.00  \n",
      "64           Beer           1.26  \n",
      "74        Spirits           2.06  \n",
      "78          Other           0.00  \n",
      "84          Other           0.00  \n",
      "86           Wine           1.83  \n",
      "97           Wine           0.00  \n",
      "99           Wine           0.00  \n"
     ]
    }
   ],
   "source": [
    "#filter those records which not appears in a given list from world alcohol consumption dataset.\n",
    "\n",
    "print(\"\\nSelect all rows which not appears in a given list:\")\n",
    "who_region = [\"Africa\", \"Eastern Mediterranean\", \"Europe\"]\n",
    "flt_wine = df[~df[\"WHO region\"].isin(who_region)]\n",
    "print(flt_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average consumption of wine per person greater than 2:\n",
      "    Year             WHO region  \\\n",
      "2   1985                 Africa   \n",
      "26  1985                 Europe   \n",
      "34  1986                 Europe   \n",
      "49  1986                 Europe   \n",
      "57  1989                 Europe   \n",
      "81  1985                 Europe   \n",
      "86  1986               Americas   \n",
      "89  1986  Eastern Mediterranean   \n",
      "96  1985                 Europe   \n",
      "\n",
      "                                              Country Beverage Types  \\\n",
      "2                                        Cte d'Ivoire           Wine   \n",
      "26  United Kingdom of Great Britain and Northern I...           Wine   \n",
      "34                                 Russian Federation           Wine   \n",
      "49                                              Malta           Wine   \n",
      "57                                            Croatia           Wine   \n",
      "81                                        Netherlands           Wine   \n",
      "86                                            Bahamas           Wine   \n",
      "89                                            Lebanon           Wine   \n",
      "96                                         Luxembourg           Wine   \n",
      "\n",
      "    Display Value  \n",
      "2            1.62  \n",
      "26           1.36  \n",
      "34           0.80  \n",
      "49           1.49  \n",
      "57           5.10  \n",
      "81           2.54  \n",
      "86           1.83  \n",
      "89           0.70  \n",
      "96           7.38  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAverage consumption of wine per person greater than 2:\")\n",
    "print(df[(df['Beverage Types'] == 'Wine') & (df['Display Value'] > .2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Find  all columns which all entries present:\n",
      "    Year       WHO region                                Country  \\\n",
      "0   1986  Western Pacific                               Viet Nam   \n",
      "1   1986         Americas                                Uruguay   \n",
      "2   1985           Africa                           Cte d'Ivoire   \n",
      "3   1986         Americas                               Colombia   \n",
      "4   1987         Americas                  Saint Kitts and Nevis   \n",
      "..   ...              ...                                    ...   \n",
      "95  1984           Africa                                  Niger   \n",
      "96  1985           Europe                             Luxembourg   \n",
      "97  1984  South-East Asia                              Indonesia   \n",
      "98  1984           Africa                      Equatorial Guinea   \n",
      "99  1985  South-East Asia  Democratic People's Republic of Korea   \n",
      "\n",
      "   Beverage Types  \n",
      "0            Wine  \n",
      "1           Other  \n",
      "2            Wine  \n",
      "3            Beer  \n",
      "4            Beer  \n",
      "..            ...  \n",
      "95          Other  \n",
      "96           Wine  \n",
      "97           Wine  \n",
      "98           Wine  \n",
      "99           Wine  \n",
      "\n",
      "[100 rows x 4 columns]\n",
      "\n",
      "Rows and columns has a NaN:\n",
      "    Display Value\n",
      "0            0.00\n",
      "1            0.50\n",
      "2            1.62\n",
      "3            4.27\n",
      "4            1.98\n",
      "..            ...\n",
      "95           0.00\n",
      "96           7.38\n",
      "97           0.00\n",
      "98           0.00\n",
      "99           0.00\n",
      "\n",
      "[100 rows x 1 columns]\n",
      "\n",
      "Drop rows with any NaNs:\n",
      "    Year       WHO region                                Country  \\\n",
      "0   1986  Western Pacific                               Viet Nam   \n",
      "1   1986         Americas                                Uruguay   \n",
      "2   1985           Africa                           Cte d'Ivoire   \n",
      "3   1986         Americas                               Colombia   \n",
      "4   1987         Americas                  Saint Kitts and Nevis   \n",
      "..   ...              ...                                    ...   \n",
      "95  1984           Africa                                  Niger   \n",
      "96  1985           Europe                             Luxembourg   \n",
      "97  1984  South-East Asia                              Indonesia   \n",
      "98  1984           Africa                      Equatorial Guinea   \n",
      "99  1985  South-East Asia  Democratic People's Republic of Korea   \n",
      "\n",
      "   Beverage Types  Display Value  \n",
      "0            Wine           0.00  \n",
      "1           Other           0.50  \n",
      "2            Wine           1.62  \n",
      "3            Beer           4.27  \n",
      "4            Beer           1.98  \n",
      "..            ...            ...  \n",
      "95          Other           0.00  \n",
      "96           Wine           7.38  \n",
      "97           Wine           0.00  \n",
      "98           Wine           0.00  \n",
      "99           Wine           0.00  \n",
      "\n",
      "[95 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#filter all columns where all entries present, check which rows and columns has a NaN and finally drop rows with any NaNs from world alcohol consumption dataset.\n",
    "\n",
    "print(\"\\nFind  all columns which all entries present:\")\n",
    "print(df.loc[:, df.notnull().all()])\n",
    "print(\"\\nRows and columns has a NaN:\")\n",
    "print(df.loc[:,df.isnull().any()])\n",
    "print(\"\\nDrop rows with any NaNs:\")\n",
    "print(df.dropna(how='any')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Grouping and Aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "student_data = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [12, 12, 13, 13, 14, 12],\n",
    "    'height': [173, 192, 186, 167, 151, 159],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split the said data on school_code wise:\n",
      "\n",
      "Group:\n",
      "s001\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S4  street1  \n",
      "\n",
      "Group:\n",
      "s002\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S2        s002     V  Gino Mcneill     17/05/2002   12     192      32   \n",
      "S5        s002     V  Gino Mcneill     11/05/2002   14     151      31   \n",
      "\n",
      "    address  \n",
      "S2  street2  \n",
      "S5  street2  \n",
      "\n",
      "Group:\n",
      "s003\n",
      "   school_code class         name date_Of_Birth   age  height  weight  address\n",
      "S3        s003    VI  Ryan Parkes     16/02/1999   13     186      33  street3\n",
      "\n",
      "Group:\n",
      "s004\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  \n",
      "\n",
      "Type of the object:\n",
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n"
     ]
    }
   ],
   "source": [
    "#split the following dataframe into groups based on school code\n",
    "\n",
    "print('\\nSplit the said data on school_code wise:')\n",
    "result = student_data.groupby(['school_code'])\n",
    "for name,group in result:\n",
    "    print(\"\\nGroup:\")\n",
    "    print(name)\n",
    "    print(group)\n",
    "print(\"\\nType of the object:\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              age        \n",
      "             mean min max\n",
      "school_code              \n",
      "s001         12.5  12  13\n",
      "s002         13.0  12  14\n",
      "s003         13.0  13  13\n",
      "s004         12.0  12  12\n"
     ]
    }
   ],
   "source": [
    "#split the following dataframe by school code and get mean, min, and max value of age for each school.\n",
    "grouped_single = student_data.groupby('school_code').agg({'age': ['mean', 'min', 'max']})\n",
    "print(grouped_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split the said data on school_code, class wise:\n",
      "\n",
      "Group:\n",
      "('s001', 'V')\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "\n",
      "Group:\n",
      "('s001', 'VI')\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S4        s001    VI  Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S4  street1  \n",
      "\n",
      "Group:\n",
      "('s002', 'V')\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S2        s002     V  Gino Mcneill     17/05/2002   12     192      32   \n",
      "S5        s002     V  Gino Mcneill     11/05/2002   14     151      31   \n",
      "\n",
      "    address  \n",
      "S2  street2  \n",
      "S5  street2  \n",
      "\n",
      "Group:\n",
      "('s003', 'VI')\n",
      "   school_code class         name date_Of_Birth   age  height  weight  address\n",
      "S3        s003    VI  Ryan Parkes     16/02/1999   13     186      33  street3\n",
      "\n",
      "Group:\n",
      "('s004', 'VI')\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  \n"
     ]
    }
   ],
   "source": [
    "#split the following given dataframe into groups based on school code and class.\n",
    "\n",
    "print('\\nSplit the said data on school_code, class wise:')\n",
    "result = student_data.groupby(['school_code', 'class'])\n",
    "for name,group in result:\n",
    "    print(\"\\nGroup:\")\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split the said data on school_code wise:\n",
      "Call school code 's001':\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S4  street1  \n",
      "\n",
      "Call school code 's004':\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  \n"
     ]
    }
   ],
   "source": [
    "print('\\nSplit the said data on school_code wise:')\n",
    "grouped = student_data.groupby(['school_code'])\n",
    "print(\"Call school code 's001':\")\n",
    "print(grouped.get_group('s001'))\n",
    "print(\"\\nCall school code 's004':\")\n",
    "print(grouped.get_group('s004'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "  book_name book_type  book_id\n",
      "0     Book1      Math        1\n",
      "1     Book2   Physics        2\n",
      "2     Book3  Computer        3\n",
      "3     Book4   Science        4\n",
      "4     Book1      Math        1\n",
      "5     Book2   Physics        2\n",
      "6     Book3  Computer        3\n",
      "7     Book5   English        5\n",
      "\n",
      "New column with count from groupby:\n",
      "  book_name book_type  count\n",
      "0     Book1      Math      2\n",
      "1     Book2   Physics      2\n",
      "2     Book3  Computer      2\n",
      "3     Book4   Science      1\n",
      "4     Book5   English      1\n"
     ]
    }
   ],
   "source": [
    "#split a given dataframe into groups and create a new column with count from GroupBy.\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "df = pd.DataFrame({\n",
    "'book_name':['Book1','Book2','Book3','Book4','Book1','Book2','Book3','Book5'],\n",
    "'book_type':['Math','Physics','Computer','Science','Math','Physics','Computer','English'],\n",
    "'book_id':[1,2,3,4,1,2,3,5]})\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nNew column with count from groupby:\")\n",
    "result = df.groupby([\"book_name\", \"book_type\"])[\"book_type\"].count().reset_index(name=\"count\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.w3resource.com/python-exercises/pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Excellent Collection of Pandas Interview Questions\n",
    "\n",
    "https://analyticsindiamag.com/10-important-pandas-interview-questions-every-beginner-must-know/\n",
    "\n",
    "https://medium.com/@kacawi/tutorial-pandas-data-structures-736ded97842\n",
    "\n",
    "https://atraininghub.com/data-analysis-with-python-and-pandas-interview-questions-and-answers/\n",
    "\n",
    "https://www.mytectra.com/interview-question/python-pandas-interview-questions-and-answers/\n",
    "\n",
    "https://www.w3resource.com/python-exercises/pandas/index.php\n",
    "\n",
    "https://www.knowledgepowerhouse.com/top-50-pandas-interview-preparation-questions/2504\n",
    "    \n",
    "https://www.kaggle.com/code/kashnitsky/topic-1-exploratory-data-analysis-with-pandas/notebook\n",
    "    \n",
    "General Pandas Exercise\n",
    "https://pynative.com/python-pandas-exercise/\n",
    "\n",
    "Simple Exercise\n",
    "https://nbviewer.jupyter.org/github/guipsamora/pandas_exercises/blob/master/01_Getting_%26_Knowing_Your_Data/Chipotle/Exercises.ipynb\n",
    "https://nbviewer.jupyter.org/github/guipsamora/pandas_exercises/blob/master/01_Getting_%26_Knowing_Your_Data/Chipotle/Exercise_with_Solutions.ipynb\n",
    "\n",
    "Filtering and Sorting Exercise\n",
    "https://nbviewer.jupyter.org/github/guipsamora/pandas_exercises/blob/master/02_Filtering_%26_Sorting/Euro12/Exercises.ipynb\n",
    "\n",
    "https://nbviewer.jupyter.org/github/guipsamora/pandas_exercises/blob/master/02_Filtering_%26_Sorting/Euro12/Exercises_with_Solutions.ipynb\n",
    "\n",
    "GroupBy Exercise\n",
    "https://nbviewer.jupyter.org/github/guipsamora/pandas_exercises/blob/master/03_Grouping/Alcohol_Consumption/Exercise.ipynb\n",
    "\n",
    "https://nbviewer.jupyter.org/github/guipsamora/pandas_exercises/blob/master/03_Grouping/Alcohol_Consumption/Exercise_with_solutions.ipynb\n",
    "\n",
    "Apply method\n",
    "https://nbviewer.jupyter.org/github/guipsamora/pandas_exercises/blob/master/04_Apply/Students_Alcohol_Consumption/Exercises.ipynb\n",
    "\n",
    "https://nbviewer.jupyter.org/github/guipsamora/pandas_exercises/blob/master/04_Apply/Students_Alcohol_Consumption/Exercises_with_solutions.ipynb\n",
    "\n",
    "Merge\n",
    "https://nbviewer.jupyter.org/github/guipsamora/pandas_exercises/blob/master/05_Merge/Auto_MPG/Exercises.ipynb\n",
    "\n",
    "https://nbviewer.jupyter.org/github/guipsamora/pandas_exercises/blob/master/05_Merge/Auto_MPG/Exercises_with_solutions.ipynb\n",
    "\n",
    "Data Vizualization\n",
    "https://nbviewer.jupyter.org/github/guipsamora/pandas_exercises/blob/master/07_Visualization/Online_Retail/Exercises.ipynb\n",
    "\n",
    "https://nbviewer.jupyter.org/github/guipsamora/pandas_exercises/blob/master/07_Visualization/Online_Retail/Exercises_with_solutions_code.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL to Pandas DataFrame \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
